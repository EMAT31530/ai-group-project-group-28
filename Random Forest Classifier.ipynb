{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r'C:\\Users\\Mollie\\Documents\\Uni 3\\AI\\AI project\\Cleaning the data\\clean_data.csv')\n",
    "df.head()\n",
    "dataX=df.iloc[:,:-1]\n",
    "dataY=df.iloc[:,-1]\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "train_ratio = 0.75\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.10\n",
    "\n",
    "# train is now 75% of the entire data set\n",
    "# the _junk suffix means that we drop that variable completely\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio)\n",
    "\n",
    "# test is now 10% of the initial data set\n",
    "# validation is now 15% of the initial data set\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf =tree.DecisionTreeClassifier()\n",
    "nosamp_clf=clf.fit(x_train,y_train)\n",
    "nosamp_prediction=nosamp_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training statistics: Counter({0: 31403, 1: 2743})\n",
      "Testing statistics: Counter({0: 4161, 1: 392})\n",
      "0.9747419283988579 0.8571428571428571 0.850632911392405 0.8538754764930113\n"
     ]
    }
   ],
   "source": [
    "#nosampling\n",
    "print(f\"Training statistics: {Counter(y_train)}\")\n",
    "print(f\"Testing statistics: {Counter(y_test)}\")\n",
    "amex_nosamp_accuracy=accuracy_score(nosamp_prediction,y_test)\n",
    "amex_nosamp_precision=precision_score(nosamp_prediction,y_test)\n",
    "amex_nosamp_recall=recall_score(nosamp_prediction,y_test)\n",
    "amex_nosamp_f1=f1_score(nosamp_prediction,y_test)\n",
    "print(amex_nosamp_accuracy,amex_nosamp_precision,amex_nosamp_recall,amex_nosamp_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training target statistics: Counter({0: 31403, 1: 31403})\n",
      "Testing target statistics: Counter({0: 4161, 1: 392})\n",
      "0.9729848451570393 0.8367346938775511 0.8475452196382429 0.8421052631578948\n"
     ]
    }
   ],
   "source": [
    "#oversampling\n",
    "#here we have oversampled so in the training set there are 31403 in each catagory\n",
    "over_sampler = RandomOverSampler(random_state=42)\n",
    "x_ov, y_ov = over_sampler.fit_resample(x_train, y_train)\n",
    "\n",
    "print(f\"Training target statistics: {Counter(y_ov)}\")\n",
    "print(f\"Testing target statistics: {Counter(y_test)}\")\n",
    "#now we make the decision tree with our new smaples\n",
    "oversamp_clf=clf.fit(x_ov,y_ov)\n",
    "oversamp_prediction=clf.predict(x_test)\n",
    "amex_oversamp_accuracy=accuracy_score(oversamp_prediction,y_test)\n",
    "amex_oversamp_precision=precision_score(oversamp_prediction,y_test)\n",
    "amex_oversamp_recall=recall_score(oversamp_prediction,y_test)\n",
    "amex_oversamp_f1=f1_score(oversamp_prediction,y_test)\n",
    "print(amex_oversamp_accuracy,amex_oversamp_precision,amex_oversamp_recall,amex_oversamp_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training target statistics: Counter({0: 2743, 1: 2743})\n",
      "Testing target statistics: Counter({0: 4161, 1: 392})\n",
      "0.9562925543597628 0.9489795918367347 0.6751361161524501 0.7889713679745494\n"
     ]
    }
   ],
   "source": [
    "#undersampling\n",
    "under_sampler = RandomUnderSampler(random_state=42)\n",
    "x_under, y_under = under_sampler.fit_resample(x_train, y_train)\n",
    "print(f\"Training target statistics: {Counter(y_under)}\")\n",
    "print(f\"Testing target statistics: {Counter(y_test)}\")\n",
    "#x_res=x_res[:,1:]\n",
    "#here we have undersampled so in the training set there are 2743 in each catagory\n",
    "#now we make the decision tree with our new smaples\n",
    "undersamp_clf=clf.fit(x_under,y_under)\n",
    "undersamp_prediction=clf.predict(x_test)\n",
    "amex_undersamp_accuracy=accuracy_score(undersamp_prediction,y_test)\n",
    "amex_undersamp_precision=precision_score(undersamp_prediction,y_test)\n",
    "amex_undersamp_recall=recall_score(undersamp_prediction,y_test)\n",
    "amex_undersamp_f1=f1_score(undersamp_prediction,y_test)\n",
    "print(amex_undersamp_accuracy,amex_undersamp_precision,amex_undersamp_recall,amex_undersamp_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training target statistics: Counter({1: 31360, 0: 31360})\n",
      "Testing target statistics: Counter({0: 4201, 1: 352})\n",
      "0.9743026575884033 0.8778409090909091 0.8067885117493473 0.8408163265306123\n"
     ]
    }
   ],
   "source": [
    "oversample_smote = SMOTE()\n",
    "x_smote, y_smote = oversample_smote.fit_resample(x_train, y_train)\n",
    "print(f\"Training target statistics: {Counter(y_smote)}\")\n",
    "print(f\"Testing target statistics: {Counter(y_test)}\")\n",
    "oversamp_smote_clf=clf.fit(x_smote,y_smote)\n",
    "oversamp_smote_prediction=clf.predict(x_test)\n",
    "amex_oversamp_smote_accuracy=accuracy_score(oversamp_smote_prediction,y_test)\n",
    "amex_oversamp_smote_precision=precision_score(oversamp_smote_prediction,y_test)\n",
    "amex_oversamp_smote_recall=recall_score(oversamp_smote_prediction,y_test)\n",
    "amex_oversamp_smote_f1=f1_score(oversamp_smote_prediction,y_test)\n",
    "print(amex_oversamp_smote_accuracy,amex_oversamp_smote_precision,amex_oversamp_smote_recall,amex_oversamp_smote_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc =ensemble.RandomForestClassifier()\n",
    "rfc_nosamp=rfc.fit(x_train,y_train)\n",
    "rfc_nosamp_prediction=rfc_nosamp.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8647045903799693, 0.05965909090909091, 0.06862745098039216, 0.06382978723404256]\n"
     ]
    }
   ],
   "source": [
    "#rfc nosampling\n",
    "amex_rfc_nosamp_accuracy=accuracy_score(rfc_nosamp_prediction,y_test)\n",
    "amex_rfc_nosamp_precision=precision_score(rfc_nosamp_prediction,y_test)\n",
    "amex_rfc_nosamp_recall=recall_score(rfc_nosamp_prediction,y_test)\n",
    "amex_rfc_nosamp_f1=f1_score(rfc_nosamp_prediction,y_test)\n",
    "rfc_nosamp_scores= [amex_rfc_nosamp_accuracy,amex_rfc_nosamp_precision,amex_rfc_nosamp_recall,amex_rfc_nosamp_f1]\n",
    "print(rfc_nosamp_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9967054689215902 0.9715909090909091 0.9855907780979827 0.9785407725321887\n"
     ]
    }
   ],
   "source": [
    "#rfc oversampling\n",
    "#now we make the decision tree with our new smaples\n",
    "rfc_oversamp=rfc.fit(x_ov,y_ov)\n",
    "rfc_oversamp_prediction=rfc.predict(x_test)\n",
    "amex_rfc_oversamp_accuracy=accuracy_score(rfc_oversamp_prediction,y_test)\n",
    "amex_rfc_oversamp_precision=precision_score(rfc_oversamp_prediction,y_test)\n",
    "amex_rfc_oversamp_recall=recall_score(rfc_oversamp_prediction,y_test)\n",
    "amex_rfc_oversamp_f1=f1_score(rfc_oversamp_prediction,y_test)\n",
    "print(amex_rfc_oversamp_accuracy,amex_rfc_oversamp_precision,amex_rfc_oversamp_recall,amex_rfc_oversamp_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9527783878761257 0.9948979591836735 0.6467661691542289 0.7839195979899498\n"
     ]
    }
   ],
   "source": [
    "#rfc oversampling\n",
    "#now we make the decision tree with our new smaples\n",
    "undersamp_rfc=rfc.fit(x_under,y_under)\n",
    "rfc_undersamp_prediction=rfc.predict(x_test)\n",
    "amex_rfc_undersamp_accuracy=accuracy_score(rfc_undersamp_prediction,y_test)\n",
    "amex_rfc_undersamp_precision=precision_score(rfc_undersamp_prediction,y_test)\n",
    "amex_rfc_undersamp_recall=recall_score(rfc_undersamp_prediction,y_test)\n",
    "amex_rfc_undersamp_f1=f1_score(rfc_undersamp_prediction,y_test)\n",
    "print(amex_rfc_undersamp_accuracy,amex_rfc_undersamp_precision,amex_rfc_undersamp_recall,amex_rfc_undersamp_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training target statistics: Counter({1: 31360, 0: 31360})\n",
      "Testing target statistics: Counter({0: 4201, 1: 352})\n",
      "0.980232813529541 0.8494318181818182 0.8898809523809523 0.869186046511628\n"
     ]
    }
   ],
   "source": [
    "oversample_smote = SMOTE()\n",
    "x_smote, y_smote = oversample_smote.fit_resample(x_train, y_train)\n",
    "print(f\"Training target statistics: {Counter(y_smote)}\")\n",
    "print(f\"Testing target statistics: {Counter(y_test)}\")\n",
    "\n",
    "rfc_oversamp_smote=rfc.fit(x_smote,y_smote)\n",
    "rfc_oversamp_smote_prediction=rfc.predict(x_test)\n",
    "amex_rfc_oversamp_smote_accuracy=accuracy_score(rfc_oversamp_smote_prediction,y_test)\n",
    "amex_rfc_oversamp_smote_precision=precision_score(rfc_oversamp_smote_prediction,y_test)\n",
    "amex_rfc_oversamp_smote_recall=recall_score(rfc_oversamp_smote_prediction,y_test)\n",
    "amex_rfc_oversamp_smote_f1=f1_score(rfc_oversamp_smote_prediction,y_test)\n",
    "print(amex_rfc_oversamp_smote_accuracy,amex_rfc_oversamp_smote_precision,amex_rfc_oversamp_smote_recall,amex_rfc_oversamp_smote_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient boosted decsion trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 4 artists>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "names=['acc','prec','rec','f1']\n",
    "plt.bar(names,rfc_nosamp_scores)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
