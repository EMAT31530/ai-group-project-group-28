{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "696cc2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras import metrics, Input\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "913ffe9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [metrics.RootMeanSquaredError(name='rms'), metrics.MeanAbsoluteError(name='mae')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "580cbecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODING_DIM = 16 #Desired Dimension\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9c8b373a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_and_train_autoencoder(X_train, metrics=METRICS):\n",
    "    \n",
    "    len_input_output = X_train.shape[-1]\n",
    "    input_ = Input(shape=(len_input_output,))\n",
    "    encoded = Dense(units=ENCODING_DIM*2, activation=\"relu\")(input_)\n",
    "    bottleneck = Dense(units=ENCODING_DIM, \n",
    "                       activation=\"relu\")(encoded)\n",
    "    decoded = Dense(units=ENCODING_DIM*2, \n",
    "                    activation=\"relu\")(bottleneck)\n",
    "    output = Dense(units=len_input_output, \n",
    "                    activation=\"linear\")(decoded)\n",
    "    #Training is performed on the entire autoencoder\n",
    "    autoencoder = Model(inputs=input_, outputs=output)\n",
    "    autoencoder.compile(optimizer='adam', loss='mean_squared_error',\n",
    "                        metrics=[metrics])\n",
    "    autoencoder.fit(X_train, X_train,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS)\n",
    "    #Use only the encoder part for dimensionality reduction\n",
    "    encoder = Model(inputs=input_, outputs=bottleneck)\n",
    "    return autoencoder, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "13d313aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('training_ROS.csv')\n",
    "qw = pd.read_csv('validation_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a1ffb92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.iloc[:,:-1], df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fe0835e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "512/512 [==============================] - 7s 9ms/step - loss: 0.0074 - rms: 0.0726 - mae: 0.0382\n",
      "Epoch 2/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 9.1966e-04 - rms: 0.0303 - mae: 0.0174\n",
      "Epoch 3/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 5.5984e-04 - rms: 0.0237 - mae: 0.0124\n",
      "Epoch 4/50\n",
      "512/512 [==============================] - 4s 8ms/step - loss: 3.6246e-04 - rms: 0.0190 - mae: 0.0094\n",
      "Epoch 5/50\n",
      "512/512 [==============================] - 3s 7ms/step - loss: 2.6789e-04 - rms: 0.0164 - mae: 0.0076\n",
      "Epoch 6/50\n",
      "512/512 [==============================] - 3s 7ms/step - loss: 2.3918e-04 - rms: 0.0155 - mae: 0.0070\n",
      "Epoch 7/50\n",
      "512/512 [==============================] - 3s 7ms/step - loss: 2.2582e-04 - rms: 0.0150 - mae: 0.0063\n",
      "Epoch 8/50\n",
      "512/512 [==============================] - 3s 7ms/step - loss: 2.1835e-04 - rms: 0.0148 - mae: 0.0059\n",
      "Epoch 9/50\n",
      "512/512 [==============================] - 3s 7ms/step - loss: 2.1488e-04 - rms: 0.0147 - mae: 0.0056\n",
      "Epoch 10/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 2.1234e-04 - rms: 0.0146 - mae: 0.0055\n",
      "Epoch 11/50\n",
      "512/512 [==============================] - 4s 8ms/step - loss: 2.1073e-04 - rms: 0.0145 - mae: 0.0054\n",
      "Epoch 12/50\n",
      "512/512 [==============================] - 3s 7ms/step - loss: 2.0783e-04 - rms: 0.0144 - mae: 0.0054\n",
      "Epoch 13/50\n",
      "512/512 [==============================] - 4s 8ms/step - loss: 2.0372e-04 - rms: 0.0143 - mae: 0.0053\n",
      "Epoch 14/50\n",
      "512/512 [==============================] - 6s 12ms/step - loss: 2.0323e-04 - rms: 0.0143 - mae: 0.0054\n",
      "Epoch 15/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.9965e-04 - rms: 0.0141 - mae: 0.0052\n",
      "Epoch 16/50\n",
      "512/512 [==============================] - 3s 7ms/step - loss: 1.9873e-04 - rms: 0.0141 - mae: 0.0052\n",
      "Epoch 17/50\n",
      "512/512 [==============================] - 3s 7ms/step - loss: 1.9698e-04 - rms: 0.0140 - mae: 0.0052\n",
      "Epoch 18/50\n",
      "512/512 [==============================] - 3s 7ms/step - loss: 1.9663e-04 - rms: 0.0140 - mae: 0.0051\n",
      "Epoch 19/50\n",
      "512/512 [==============================] - 3s 7ms/step - loss: 1.9664e-04 - rms: 0.0140 - mae: 0.0051\n",
      "Epoch 20/50\n",
      "512/512 [==============================] - 3s 7ms/step - loss: 1.9540e-04 - rms: 0.0140 - mae: 0.0050\n",
      "Epoch 21/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.9569e-04 - rms: 0.0140 - mae: 0.0051\n",
      "Epoch 22/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.9570e-04 - rms: 0.0140 - mae: 0.0051\n",
      "Epoch 23/50\n",
      "512/512 [==============================] - 9s 17ms/step - loss: 1.9516e-04 - rms: 0.0140 - mae: 0.0051\n",
      "Epoch 24/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.9387e-04 - rms: 0.0139 - mae: 0.0049\n",
      "Epoch 25/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.9493e-04 - rms: 0.0140 - mae: 0.0050\n",
      "Epoch 26/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.9517e-04 - rms: 0.0140 - mae: 0.0051\n",
      "Epoch 27/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.9323e-04 - rms: 0.0139 - mae: 0.0050\n",
      "Epoch 28/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.9064e-04 - rms: 0.0138 - mae: 0.0052\n",
      "Epoch 29/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.8613e-04 - rms: 0.0136 - mae: 0.0051\n",
      "Epoch 30/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.8408e-04 - rms: 0.0136 - mae: 0.0051\n",
      "Epoch 31/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.8308e-04 - rms: 0.0135 - mae: 0.0050\n",
      "Epoch 32/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.8264e-04 - rms: 0.0135 - mae: 0.0051\n",
      "Epoch 33/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.8073e-04 - rms: 0.0134 - mae: 0.0050\n",
      "Epoch 34/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.8101e-04 - rms: 0.0135 - mae: 0.0050\n",
      "Epoch 35/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.7957e-04 - rms: 0.0134 - mae: 0.0049\n",
      "Epoch 36/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.7967e-04 - rms: 0.0134 - mae: 0.0050\n",
      "Epoch 37/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.7916e-04 - rms: 0.0134 - mae: 0.0050\n",
      "Epoch 38/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.7881e-04 - rms: 0.0134 - mae: 0.0050\n",
      "Epoch 39/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.7951e-04 - rms: 0.0134 - mae: 0.0050\n",
      "Epoch 40/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.7841e-04 - rms: 0.0134 - mae: 0.0049\n",
      "Epoch 41/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.7854e-04 - rms: 0.0134 - mae: 0.0049\n",
      "Epoch 42/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.7774e-04 - rms: 0.0133 - mae: 0.0049\n",
      "Epoch 43/50\n",
      "512/512 [==============================] - 3s 7ms/step - loss: 1.7790e-04 - rms: 0.0133 - mae: 0.0049\n",
      "Epoch 44/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.7768e-04 - rms: 0.0133 - mae: 0.0049\n",
      "Epoch 45/50\n",
      "512/512 [==============================] - 4s 8ms/step - loss: 1.7692e-04 - rms: 0.0133 - mae: 0.0049\n",
      "Epoch 46/50\n",
      "512/512 [==============================] - 5s 9ms/step - loss: 1.7760e-04 - rms: 0.0133 - mae: 0.0049\n",
      "Epoch 47/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.7754e-04 - rms: 0.0133 - mae: 0.0049\n",
      "Epoch 48/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.7617e-04 - rms: 0.0133 - mae: 0.0049\n",
      "Epoch 49/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.7640e-04 - rms: 0.0133 - mae: 0.0049\n",
      "Epoch 50/50\n",
      "512/512 [==============================] - 4s 8ms/step - loss: 1.7544e-04 - rms: 0.0132 - mae: 0.0048\n"
     ]
    }
   ],
   "source": [
    "auto, encode = make_and_train_autoencoder(X, metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1ae7b067",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = encode.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1ca56343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32710, 16)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e1749356",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = np.array(q)\n",
    "df = pd.DataFrame(data=q,index=None,columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "87f18d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.283456</td>\n",
       "      <td>0.577016</td>\n",
       "      <td>0.423019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250961</td>\n",
       "      <td>0.202846</td>\n",
       "      <td>0.481518</td>\n",
       "      <td>0.244313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.454076</td>\n",
       "      <td>0.393439</td>\n",
       "      <td>0.548409</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.185507</td>\n",
       "      <td>0.648040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.493598</td>\n",
       "      <td>0.541534</td>\n",
       "      <td>0.530520</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.181428</td>\n",
       "      <td>0.399625</td>\n",
       "      <td>0.830677</td>\n",
       "      <td>0.337497</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.638950</td>\n",
       "      <td>0.381134</td>\n",
       "      <td>0.729409</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.136083</td>\n",
       "      <td>0.676449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.403154</td>\n",
       "      <td>0.321343</td>\n",
       "      <td>0.285773</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.303656</td>\n",
       "      <td>0.857309</td>\n",
       "      <td>0.391485</td>\n",
       "      <td>0.756702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.486127</td>\n",
       "      <td>0.419870</td>\n",
       "      <td>0.800637</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.240612</td>\n",
       "      <td>0.818876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.500504</td>\n",
       "      <td>0.489318</td>\n",
       "      <td>0.190704</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.183143</td>\n",
       "      <td>0.559673</td>\n",
       "      <td>0.443194</td>\n",
       "      <td>0.312199</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.369171</td>\n",
       "      <td>0.542243</td>\n",
       "      <td>0.441686</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.236049</td>\n",
       "      <td>0.453401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.486707</td>\n",
       "      <td>0.445970</td>\n",
       "      <td>0.184550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.146938</td>\n",
       "      <td>0.422056</td>\n",
       "      <td>0.190994</td>\n",
       "      <td>0.265513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.326501</td>\n",
       "      <td>0.416364</td>\n",
       "      <td>0.315365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.188302</td>\n",
       "      <td>0.372284</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32705</th>\n",
       "      <td>0.535559</td>\n",
       "      <td>0.441531</td>\n",
       "      <td>0.155430</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.098877</td>\n",
       "      <td>0.410986</td>\n",
       "      <td>0.186439</td>\n",
       "      <td>0.152110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.420630</td>\n",
       "      <td>0.293837</td>\n",
       "      <td>0.362307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125869</td>\n",
       "      <td>0.459955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32706</th>\n",
       "      <td>0.406270</td>\n",
       "      <td>0.635256</td>\n",
       "      <td>0.557693</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.418377</td>\n",
       "      <td>0.540109</td>\n",
       "      <td>0.657915</td>\n",
       "      <td>0.913499</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.660840</td>\n",
       "      <td>0.443102</td>\n",
       "      <td>0.987366</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.283028</td>\n",
       "      <td>1.193918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32707</th>\n",
       "      <td>0.308616</td>\n",
       "      <td>0.412434</td>\n",
       "      <td>0.616408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.407357</td>\n",
       "      <td>0.596448</td>\n",
       "      <td>0.612854</td>\n",
       "      <td>0.690864</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.541341</td>\n",
       "      <td>0.506517</td>\n",
       "      <td>1.226618</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.197294</td>\n",
       "      <td>1.111643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32708</th>\n",
       "      <td>0.309377</td>\n",
       "      <td>0.101572</td>\n",
       "      <td>0.228378</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.229550</td>\n",
       "      <td>0.640677</td>\n",
       "      <td>0.003570</td>\n",
       "      <td>0.597411</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.260949</td>\n",
       "      <td>0.359638</td>\n",
       "      <td>0.665072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100872</td>\n",
       "      <td>0.632721</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32709</th>\n",
       "      <td>0.703601</td>\n",
       "      <td>0.911759</td>\n",
       "      <td>0.324670</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.293035</td>\n",
       "      <td>0.569388</td>\n",
       "      <td>0.660506</td>\n",
       "      <td>0.359590</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.620322</td>\n",
       "      <td>0.677790</td>\n",
       "      <td>0.536682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.368630</td>\n",
       "      <td>1.035978</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32710 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2    3         4         5         6  \\\n",
       "0      0.283456  0.577016  0.423019  0.0  0.250961  0.202846  0.481518   \n",
       "1      0.493598  0.541534  0.530520  0.0  0.181428  0.399625  0.830677   \n",
       "2      0.403154  0.321343  0.285773  0.0  0.303656  0.857309  0.391485   \n",
       "3      0.500504  0.489318  0.190704  0.0  0.183143  0.559673  0.443194   \n",
       "4      0.486707  0.445970  0.184550  0.0  0.146938  0.422056  0.190994   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "32705  0.535559  0.441531  0.155430  0.0  0.098877  0.410986  0.186439   \n",
       "32706  0.406270  0.635256  0.557693  0.0  0.418377  0.540109  0.657915   \n",
       "32707  0.308616  0.412434  0.616408  0.0  0.407357  0.596448  0.612854   \n",
       "32708  0.309377  0.101572  0.228378  0.0  0.229550  0.640677  0.003570   \n",
       "32709  0.703601  0.911759  0.324670  0.0  0.293035  0.569388  0.660506   \n",
       "\n",
       "              7    8         9        10        11   12        13        14  \\\n",
       "0      0.244313  0.0  0.454076  0.393439  0.548409  0.0  0.185507  0.648040   \n",
       "1      0.337497  0.0  0.638950  0.381134  0.729409  0.0  0.136083  0.676449   \n",
       "2      0.756702  0.0  0.486127  0.419870  0.800637  0.0  0.240612  0.818876   \n",
       "3      0.312199  0.0  0.369171  0.542243  0.441686  0.0  0.236049  0.453401   \n",
       "4      0.265513  0.0  0.326501  0.416364  0.315365  0.0  0.188302  0.372284   \n",
       "...         ...  ...       ...       ...       ...  ...       ...       ...   \n",
       "32705  0.152110  0.0  0.420630  0.293837  0.362307  0.0  0.125869  0.459955   \n",
       "32706  0.913499  0.0  0.660840  0.443102  0.987366  0.0  0.283028  1.193918   \n",
       "32707  0.690864  0.0  0.541341  0.506517  1.226618  0.0  0.197294  1.111643   \n",
       "32708  0.597411  0.0  0.260949  0.359638  0.665072  0.0  0.100872  0.632721   \n",
       "32709  0.359590  0.0  0.620322  0.677790  0.536682  0.0  0.368630  1.035978   \n",
       "\n",
       "        15  label  \n",
       "0      0.0    0.0  \n",
       "1      0.0    1.0  \n",
       "2      0.0    0.0  \n",
       "3      0.0    0.0  \n",
       "4      0.0    0.0  \n",
       "...    ...    ...  \n",
       "32705  0.0    1.0  \n",
       "32706  0.0    1.0  \n",
       "32707  0.0    1.0  \n",
       "32708  0.0    1.0  \n",
       "32709  0.0    1.0  \n",
       "\n",
       "[32710 rows x 17 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = y\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "841015b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('training_ros_autoencoded_16.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f693aaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "156/156 [==============================] - 3s 7ms/step - loss: 0.0246 - rms: 0.0768 - mae: 0.0262\n",
      "Epoch 2/50\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 0.0047 - rms: 0.0684 - mae: 0.0447\n",
      "Epoch 3/50\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 0.0019 - rms: 0.0435 - mae: 0.0278\n",
      "Epoch 4/50\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 0.0012 - rms: 0.0340 - mae: 0.0202\n",
      "Epoch 5/50\n",
      "156/156 [==============================] - 1s 9ms/step - loss: 9.1826e-04 - rms: 0.0303 - mae: 0.0171\n",
      "Epoch 6/50\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 7.5311e-04 - rms: 0.0274 - mae: 0.0150\n",
      "Epoch 7/50\n",
      "156/156 [==============================] - 1s 9ms/step - loss: 5.9889e-04 - rms: 0.0245 - mae: 0.0131\n",
      "Epoch 8/50\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 4.8097e-04 - rms: 0.0219 - mae: 0.0112\n",
      "Epoch 9/50\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 4.1645e-04 - rms: 0.0204 - mae: 0.0102\n",
      "Epoch 10/50\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 3.6480e-04 - rms: 0.0191 - mae: 0.0096\n",
      "Epoch 11/50\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 3.1595e-04 - rms: 0.0178 - mae: 0.0090\n",
      "Epoch 12/50\n",
      "156/156 [==============================] - 1s 9ms/step - loss: 2.6541e-04 - rms: 0.0163 - mae: 0.0081\n",
      "Epoch 13/50\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 2.2814e-04 - rms: 0.0151 - mae: 0.0074\n",
      "Epoch 14/50\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 2.0203e-04 - rms: 0.0142 - mae: 0.0068\n",
      "Epoch 15/50\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 1.8401e-04 - rms: 0.0136 - mae: 0.0064\n",
      "Epoch 16/50\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 1.7115e-04 - rms: 0.0131 - mae: 0.0061\n",
      "Epoch 17/50\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 1.6173e-04 - rms: 0.0127 - mae: 0.0058\n",
      "Epoch 18/50\n",
      "156/156 [==============================] - 1s 8ms/step - loss: 1.5301e-04 - rms: 0.0124 - mae: 0.0056\n",
      "Epoch 19/50\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 1.4760e-04 - rms: 0.0121 - mae: 0.0054\n",
      "Epoch 20/50\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 1.4052e-04 - rms: 0.0119 - mae: 0.0052\n",
      "Epoch 21/50\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 1.3386e-04 - rms: 0.0116 - mae: 0.0049\n",
      "Epoch 22/50\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 1.2873e-04 - rms: 0.0113 - mae: 0.0047\n",
      "Epoch 23/50\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 1.2502e-04 - rms: 0.0112 - mae: 0.0046\n",
      "Epoch 24/50\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 1.2210e-04 - rms: 0.0110 - mae: 0.0044\n",
      "Epoch 25/50\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 1.1913e-04 - rms: 0.0109 - mae: 0.0042\n",
      "Epoch 26/50\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 1.1682e-04 - rms: 0.0108 - mae: 0.0042\n",
      "Epoch 27/50\n",
      "156/156 [==============================] - 1s 8ms/step - loss: 1.1613e-04 - rms: 0.0108 - mae: 0.0042\n",
      "Epoch 28/50\n",
      "156/156 [==============================] - 1s 9ms/step - loss: 1.1560e-04 - rms: 0.0108 - mae: 0.0042\n",
      "Epoch 29/50\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 1.1269e-04 - rms: 0.0106 - mae: 0.0040\n",
      "Epoch 30/50\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 1.1226e-04 - rms: 0.0106 - mae: 0.0040\n",
      "Epoch 31/50\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 1.1242e-04 - rms: 0.0106 - mae: 0.0040\n",
      "Epoch 32/50\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 1.1275e-04 - rms: 0.0106 - mae: 0.0041\n",
      "Epoch 33/50\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 1.0894e-04 - rms: 0.0104 - mae: 0.0038\n",
      "Epoch 34/50\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 1.0857e-04 - rms: 0.0104 - mae: 0.0038\n",
      "Epoch 35/50\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 1.0894e-04 - rms: 0.0104 - mae: 0.0038\n",
      "Epoch 36/50\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 1.0802e-04 - rms: 0.0104 - mae: 0.0038\n",
      "Epoch 37/50\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 1.0699e-04 - rms: 0.0103 - mae: 0.0037\n",
      "Epoch 38/50\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 1.0740e-04 - rms: 0.0104 - mae: 0.0037\n",
      "Epoch 39/50\n",
      "156/156 [==============================] - 1s 8ms/step - loss: 1.0745e-04 - rms: 0.0104 - mae: 0.0038\n",
      "Epoch 40/50\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 1.0781e-04 - rms: 0.0104 - mae: 0.0038\n",
      "Epoch 41/50\n",
      "156/156 [==============================] - 1s 9ms/step - loss: 1.0633e-04 - rms: 0.0103 - mae: 0.0037\n",
      "Epoch 42/50\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 1.0671e-04 - rms: 0.0103 - mae: 0.0038\n",
      "Epoch 43/50\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 1.0662e-04 - rms: 0.0103 - mae: 0.0037\n",
      "Epoch 44/50\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 1.0600e-04 - rms: 0.0103 - mae: 0.0037\n",
      "Epoch 45/50\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 1.0558e-04 - rms: 0.0103 - mae: 0.0037\n",
      "Epoch 46/50\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 1.0648e-04 - rms: 0.0103 - mae: 0.0037\n",
      "Epoch 47/50\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 1.0547e-04 - rms: 0.0103 - mae: 0.0036\n",
      "Epoch 48/50\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 1.0521e-04 - rms: 0.0103 - mae: 0.0036\n",
      "Epoch 49/50\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 1.0529e-04 - rms: 0.0103 - mae: 0.0036\n",
      "Epoch 50/50\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 1.0560e-04 - rms: 0.0103 - mae: 0.0037\n"
     ]
    }
   ],
   "source": [
    "#### CNN autoencode\n",
    "df = pd.read_csv('training_CNN.csv')\n",
    "X, y = df.iloc[:,:-1], df.iloc[:, -1]\n",
    "auto, encode = make_and_train_autoencoder(X, metrics=METRICS)\n",
    "q = encode.predict(X)\n",
    "w = np.array(q)\n",
    "df = pd.DataFrame(data=w,index=None,columns=None)\n",
    "df['label'] = y\n",
    "df.to_csv('training_cnn_autoencoded_16.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a273d6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "146/146 [==============================] - 3s 7ms/step - loss: 0.0237 - rms: 0.1071 - mae: 0.0477\n",
      "Epoch 2/50\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 0.0046 - rms: 0.0680 - mae: 0.0456\n",
      "Epoch 3/50\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 0.0021 - rms: 0.0463 - mae: 0.0299\n",
      "Epoch 4/50\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 0.0014 - rms: 0.0369 - mae: 0.0230\n",
      "Epoch 5/50\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 9.7783e-04 - rms: 0.0313 - mae: 0.0186\n",
      "Epoch 6/50\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 7.4698e-04 - rms: 0.0273 - mae: 0.0156\n",
      "Epoch 7/50\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 6.1093e-04 - rms: 0.0247 - mae: 0.0136\n",
      "Epoch 8/50\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 5.3034e-04 - rms: 0.0230 - mae: 0.0122\n",
      "Epoch 9/50\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 4.7710e-04 - rms: 0.0218 - mae: 0.0111\n",
      "Epoch 10/50\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 4.4518e-04 - rms: 0.0211 - mae: 0.0107\n",
      "Epoch 11/50\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 4.1211e-04 - rms: 0.0203 - mae: 0.0101\n",
      "Epoch 12/50\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 3.8873e-04 - rms: 0.0197 - mae: 0.0098\n",
      "Epoch 13/50\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 3.7124e-04 - rms: 0.0193 - mae: 0.0094\n",
      "Epoch 14/50\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 3.5717e-04 - rms: 0.0189 - mae: 0.0091\n",
      "Epoch 15/50\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 3.4787e-04 - rms: 0.0187 - mae: 0.0089\n",
      "Epoch 16/50\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 3.4169e-04 - rms: 0.0185 - mae: 0.0087\n",
      "Epoch 17/50\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 3.3513e-04 - rms: 0.0183 - mae: 0.0084\n",
      "Epoch 18/50\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 3.3617e-04 - rms: 0.0183 - mae: 0.0085\n",
      "Epoch 19/50\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 3.2834e-04 - rms: 0.0181 - mae: 0.0081\n",
      "Epoch 20/50\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 3.2621e-04 - rms: 0.0181 - mae: 0.0081\n",
      "Epoch 21/50\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 3.2521e-04 - rms: 0.0180 - mae: 0.0080\n",
      "Epoch 22/50\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 3.2464e-04 - rms: 0.0180 - mae: 0.0080\n",
      "Epoch 23/50\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 3.2052e-04 - rms: 0.0179 - mae: 0.0079\n",
      "Epoch 24/50\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 3.1771e-04 - rms: 0.0178 - mae: 0.0078\n",
      "Epoch 25/50\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 3.1559e-04 - rms: 0.0178 - mae: 0.0078\n",
      "Epoch 26/50\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 3.1116e-04 - rms: 0.0176 - mae: 0.0076\n",
      "Epoch 27/50\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 3.1182e-04 - rms: 0.0177 - mae: 0.0077\n",
      "Epoch 28/50\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 3.0742e-04 - rms: 0.0175 - mae: 0.0076\n",
      "Epoch 29/50\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 3.0621e-04 - rms: 0.0175 - mae: 0.0076\n",
      "Epoch 30/50\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 3.0059e-04 - rms: 0.0173 - mae: 0.0074\n",
      "Epoch 31/50\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 3.0908e-04 - rms: 0.0176 - mae: 0.0079\n",
      "Epoch 32/50\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 2.9926e-04 - rms: 0.0173 - mae: 0.0076\n",
      "Epoch 33/50\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 2.9528e-04 - rms: 0.0172 - mae: 0.0075\n",
      "Epoch 34/50\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 2.9045e-04 - rms: 0.0170 - mae: 0.0075\n",
      "Epoch 35/50\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 2.7418e-04 - rms: 0.0166 - mae: 0.0074\n",
      "Epoch 36/50\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 2.6557e-04 - rms: 0.0163 - mae: 0.0073\n",
      "Epoch 37/50\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 2.6071e-04 - rms: 0.0161 - mae: 0.0072\n",
      "Epoch 38/50\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 2.5641e-04 - rms: 0.0160 - mae: 0.0070\n",
      "Epoch 39/50\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 2.5552e-04 - rms: 0.0160 - mae: 0.0071\n",
      "Epoch 40/50\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 2.5143e-04 - rms: 0.0159 - mae: 0.0069\n",
      "Epoch 41/50\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 2.4947e-04 - rms: 0.0158 - mae: 0.0068\n",
      "Epoch 42/50\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 2.4519e-04 - rms: 0.0157 - mae: 0.0066\n",
      "Epoch 43/50\n",
      "146/146 [==============================] - 1s 8ms/step - loss: 2.4444e-04 - rms: 0.0156 - mae: 0.0065\n",
      "Epoch 44/50\n",
      "146/146 [==============================] - 1s 8ms/step - loss: 2.4140e-04 - rms: 0.0155 - mae: 0.0064\n",
      "Epoch 45/50\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 2.3874e-04 - rms: 0.0155 - mae: 0.0062\n",
      "Epoch 46/50\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 2.3784e-04 - rms: 0.0154 - mae: 0.0061\n",
      "Epoch 47/50\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 2.3641e-04 - rms: 0.0154 - mae: 0.0060\n",
      "Epoch 48/50\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 2.3457e-04 - rms: 0.0153 - mae: 0.0060\n",
      "Epoch 49/50\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 2.3254e-04 - rms: 0.0152 - mae: 0.0058\n",
      "Epoch 50/50\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 2.3152e-04 - rms: 0.0152 - mae: 0.0059\n"
     ]
    }
   ],
   "source": [
    "#### CNN autoencode\n",
    "df = pd.read_csv('training_RUS.csv')\n",
    "X, y = df.iloc[:,:-1], df.iloc[:, -1]\n",
    "auto, encode = make_and_train_autoencoder(X, metrics=METRICS)\n",
    "q = encode.predict(X)\n",
    "w = np.array(q)\n",
    "df = pd.DataFrame(data=w,index=None,columns=None)\n",
    "df['label'] = y\n",
    "df.to_csv('training_rus_autoencoded_16.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e4e7f978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "512/512 [==============================] - 7s 9ms/step - loss: 0.0075 - rms: 0.0768 - mae: 0.0390\n",
      "Epoch 2/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 6.4634e-04 - rms: 0.0254 - mae: 0.0147\n",
      "Epoch 3/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 2.9511e-04 - rms: 0.0172 - mae: 0.0089\n",
      "Epoch 4/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 2.1516e-04 - rms: 0.0147 - mae: 0.0072\n",
      "Epoch 5/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.6579e-04 - rms: 0.0129 - mae: 0.0061\n",
      "Epoch 6/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.3538e-04 - rms: 0.0116 - mae: 0.0051\n",
      "Epoch 7/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.1969e-04 - rms: 0.0109 - mae: 0.0047\n",
      "Epoch 8/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.1264e-04 - rms: 0.0106 - mae: 0.0045\n",
      "Epoch 9/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.0944e-04 - rms: 0.0105 - mae: 0.0044\n",
      "Epoch 10/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.0811e-04 - rms: 0.0104 - mae: 0.0043\n",
      "Epoch 11/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.0694e-04 - rms: 0.0103 - mae: 0.0042\n",
      "Epoch 12/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.0568e-04 - rms: 0.0103 - mae: 0.0042\n",
      "Epoch 13/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.0597e-04 - rms: 0.0103 - mae: 0.0041\n",
      "Epoch 14/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.0524e-04 - rms: 0.0103 - mae: 0.0041\n",
      "Epoch 15/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.0481e-04 - rms: 0.0102 - mae: 0.0041\n",
      "Epoch 16/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.0424e-04 - rms: 0.0102 - mae: 0.0040\n",
      "Epoch 17/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.0409e-04 - rms: 0.0102 - mae: 0.0040\n",
      "Epoch 18/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.0336e-04 - rms: 0.0102 - mae: 0.0039\n",
      "Epoch 19/50\n",
      "512/512 [==============================] - 3s 7ms/step - loss: 1.0292e-04 - rms: 0.0101 - mae: 0.0039\n",
      "Epoch 20/50\n",
      "512/512 [==============================] - 3s 7ms/step - loss: 1.0253e-04 - rms: 0.0101 - mae: 0.0039\n",
      "Epoch 21/50\n",
      "512/512 [==============================] - 3s 7ms/step - loss: 1.0252e-04 - rms: 0.0101 - mae: 0.0040\n",
      "Epoch 22/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.0217e-04 - rms: 0.0101 - mae: 0.0039\n",
      "Epoch 23/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.0184e-04 - rms: 0.0101 - mae: 0.0039\n",
      "Epoch 24/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.0107e-04 - rms: 0.0101 - mae: 0.0039\n",
      "Epoch 25/50\n",
      "512/512 [==============================] - 3s 7ms/step - loss: 1.0083e-04 - rms: 0.0100 - mae: 0.0039\n",
      "Epoch 26/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.0161e-04 - rms: 0.0101 - mae: 0.0040\n",
      "Epoch 27/50\n",
      "512/512 [==============================] - 3s 7ms/step - loss: 1.0092e-04 - rms: 0.0100 - mae: 0.0039\n",
      "Epoch 28/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.0075e-04 - rms: 0.0100 - mae: 0.0039\n",
      "Epoch 29/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.0090e-04 - rms: 0.0100 - mae: 0.0039\n",
      "Epoch 30/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 9.9917e-05 - rms: 0.0100 - mae: 0.0038\n",
      "Epoch 31/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.0032e-04 - rms: 0.0100 - mae: 0.0039\n",
      "Epoch 32/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 9.9789e-05 - rms: 0.0100 - mae: 0.0038\n",
      "Epoch 33/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 9.9851e-05 - rms: 0.0100 - mae: 0.0039\n",
      "Epoch 34/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.0041e-04 - rms: 0.0100 - mae: 0.0039\n",
      "Epoch 35/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 9.8736e-05 - rms: 0.0099 - mae: 0.0038\n",
      "Epoch 36/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 9.9251e-05 - rms: 0.0100 - mae: 0.0038\n",
      "Epoch 37/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 9.8951e-05 - rms: 0.0099 - mae: 0.0038\n",
      "Epoch 38/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 9.9036e-05 - rms: 0.0100 - mae: 0.0038\n",
      "Epoch 39/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 9.8655e-05 - rms: 0.0099 - mae: 0.0037\n",
      "Epoch 40/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 9.8194e-05 - rms: 0.0099 - mae: 0.0037\n",
      "Epoch 41/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 9.8448e-05 - rms: 0.0099 - mae: 0.0037\n",
      "Epoch 42/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 9.8864e-05 - rms: 0.0099 - mae: 0.0037\n",
      "Epoch 43/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 9.7955e-05 - rms: 0.0099 - mae: 0.0036\n",
      "Epoch 44/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 9.9057e-05 - rms: 0.0100 - mae: 0.0037\n",
      "Epoch 45/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 9.8212e-05 - rms: 0.0099 - mae: 0.0036\n",
      "Epoch 46/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 9.8022e-05 - rms: 0.0099 - mae: 0.0036\n",
      "Epoch 47/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 9.7664e-05 - rms: 0.0099 - mae: 0.0036\n",
      "Epoch 48/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 9.8238e-05 - rms: 0.0099 - mae: 0.0036\n",
      "Epoch 49/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 9.8072e-05 - rms: 0.0099 - mae: 0.0037\n",
      "Epoch 50/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 9.7797e-05 - rms: 0.0099 - mae: 0.0036\n"
     ]
    }
   ],
   "source": [
    "#### CNN autoencode\n",
    "df = pd.read_csv('training_smote.csv')\n",
    "X, y = df.iloc[:,:-1], df.iloc[:, -1]\n",
    "auto, encode = make_and_train_autoencoder(X, metrics=METRICS)\n",
    "q = encode.predict(X)\n",
    "w = np.array(q)\n",
    "df = pd.DataFrame(data=w,index=None,columns=None)\n",
    "df['label'] = y\n",
    "df.to_csv('training_smote_autoencoded_16.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439c2da9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
