{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "39ec5d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras import metrics, Input\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e9a1ae9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [metrics.RootMeanSquaredError(name='rms'), metrics.MeanAbsoluteError(name='mae')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d4374a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODING_DIM = 16 #Desired Dimension\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b24afe18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_and_train_autoencoder(X_train, metrics=METRICS):\n",
    "    \n",
    "    len_input_output = X_train.shape[-1]\n",
    "    input_ = Input(shape=(len_input_output,))\n",
    "    encoded = Dense(units=ENCODING_DIM*2, activation=\"relu\")(input_)\n",
    "    bottleneck = Dense(units=ENCODING_DIM, \n",
    "                       activation=\"relu\")(encoded)\n",
    "    decoded = Dense(units=ENCODING_DIM*2, \n",
    "                    activation=\"relu\")(bottleneck)\n",
    "    output = Dense(units=len_input_output, \n",
    "                    activation=\"linear\")(decoded)\n",
    "    #Training is performed on the entire autoencoder\n",
    "    autoencoder = Model(inputs=input_, outputs=output)\n",
    "    autoencoder.compile(optimizer='adam', loss='mean_squared_error',\n",
    "                        metrics=[metrics])\n",
    "    autoencoder.fit(X_train, X_train,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS)\n",
    "    #Use only the encoder part for dimensionality reduction\n",
    "    encoder = Model(inputs=input_, outputs=bottleneck)\n",
    "    return autoencoder, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9d2ec8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('training_ROS.csv')\n",
    "qw = pd.read_csv('validation_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5123d6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.iloc[:,:-1], df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e32652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "512/512 [==============================] - 7s 9ms/step - loss: 0.0074 - rms: 0.0726 - mae: 0.0382\n",
      "Epoch 2/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 9.1966e-04 - rms: 0.0303 - mae: 0.0174\n",
      "Epoch 3/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 5.5984e-04 - rms: 0.0237 - mae: 0.0124\n",
      "Epoch 4/50\n",
      "512/512 [==============================] - 4s 8ms/step - loss: 3.6246e-04 - rms: 0.0190 - mae: 0.0094\n",
      "Epoch 5/50\n",
      "512/512 [==============================] - 3s 7ms/step - loss: 2.6789e-04 - rms: 0.0164 - mae: 0.0076\n",
      "Epoch 6/50\n",
      "512/512 [==============================] - 3s 7ms/step - loss: 2.3918e-04 - rms: 0.0155 - mae: 0.0070\n",
      "Epoch 7/50\n",
      "512/512 [==============================] - 3s 7ms/step - loss: 2.2582e-04 - rms: 0.0150 - mae: 0.0063\n",
      "Epoch 8/50\n",
      "512/512 [==============================] - 3s 7ms/step - loss: 2.1835e-04 - rms: 0.0148 - mae: 0.0059\n",
      "Epoch 9/50\n",
      "512/512 [==============================] - 3s 7ms/step - loss: 2.1488e-04 - rms: 0.0147 - mae: 0.0056\n",
      "Epoch 10/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 2.1234e-04 - rms: 0.0146 - mae: 0.0055\n",
      "Epoch 11/50\n",
      "512/512 [==============================] - 4s 8ms/step - loss: 2.1073e-04 - rms: 0.0145 - mae: 0.0054\n",
      "Epoch 12/50\n",
      "512/512 [==============================] - 3s 7ms/step - loss: 2.0783e-04 - rms: 0.0144 - mae: 0.0054\n",
      "Epoch 13/50\n",
      "512/512 [==============================] - 4s 8ms/step - loss: 2.0372e-04 - rms: 0.0143 - mae: 0.0053\n",
      "Epoch 14/50\n",
      "512/512 [==============================] - 6s 12ms/step - loss: 2.0323e-04 - rms: 0.0143 - mae: 0.0054\n",
      "Epoch 15/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.9965e-04 - rms: 0.0141 - mae: 0.0052\n",
      "Epoch 16/50\n",
      "512/512 [==============================] - 3s 7ms/step - loss: 1.9873e-04 - rms: 0.0141 - mae: 0.0052\n",
      "Epoch 17/50\n",
      "512/512 [==============================] - 3s 7ms/step - loss: 1.9698e-04 - rms: 0.0140 - mae: 0.0052\n",
      "Epoch 18/50\n",
      "512/512 [==============================] - 3s 7ms/step - loss: 1.9663e-04 - rms: 0.0140 - mae: 0.0051\n",
      "Epoch 19/50\n",
      "512/512 [==============================] - 3s 7ms/step - loss: 1.9664e-04 - rms: 0.0140 - mae: 0.0051\n",
      "Epoch 20/50\n",
      "512/512 [==============================] - 3s 7ms/step - loss: 1.9540e-04 - rms: 0.0140 - mae: 0.0050\n",
      "Epoch 21/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.9569e-04 - rms: 0.0140 - mae: 0.0051\n",
      "Epoch 22/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.9570e-04 - rms: 0.0140 - mae: 0.0051\n",
      "Epoch 23/50\n",
      "512/512 [==============================] - 9s 17ms/step - loss: 1.9516e-04 - rms: 0.0140 - mae: 0.0051\n",
      "Epoch 24/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.9387e-04 - rms: 0.0139 - mae: 0.0049\n",
      "Epoch 25/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.9493e-04 - rms: 0.0140 - mae: 0.0050\n",
      "Epoch 26/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.9517e-04 - rms: 0.0140 - mae: 0.0051\n",
      "Epoch 27/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.9323e-04 - rms: 0.0139 - mae: 0.0050\n",
      "Epoch 28/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.9064e-04 - rms: 0.0138 - mae: 0.0052\n",
      "Epoch 29/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.8613e-04 - rms: 0.0136 - mae: 0.0051\n",
      "Epoch 30/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.8408e-04 - rms: 0.0136 - mae: 0.0051\n",
      "Epoch 31/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.8308e-04 - rms: 0.0135 - mae: 0.0050\n",
      "Epoch 32/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.8264e-04 - rms: 0.0135 - mae: 0.0051\n",
      "Epoch 33/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.8073e-04 - rms: 0.0134 - mae: 0.0050\n",
      "Epoch 34/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.8101e-04 - rms: 0.0135 - mae: 0.0050\n",
      "Epoch 35/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.7957e-04 - rms: 0.0134 - mae: 0.0049\n",
      "Epoch 36/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.7967e-04 - rms: 0.0134 - mae: 0.0050\n",
      "Epoch 37/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.7916e-04 - rms: 0.0134 - mae: 0.0050\n",
      "Epoch 38/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.7881e-04 - rms: 0.0134 - mae: 0.0050\n",
      "Epoch 39/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.7951e-04 - rms: 0.0134 - mae: 0.0050\n",
      "Epoch 40/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.7841e-04 - rms: 0.0134 - mae: 0.0049\n",
      "Epoch 41/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.7854e-04 - rms: 0.0134 - mae: 0.0049\n",
      "Epoch 42/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.7774e-04 - rms: 0.0133 - mae: 0.0049\n",
      "Epoch 43/50\n",
      "512/512 [==============================] - 3s 7ms/step - loss: 1.7790e-04 - rms: 0.0133 - mae: 0.0049\n",
      "Epoch 44/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 1.7768e-04 - rms: 0.0133 - mae: 0.0049\n",
      "Epoch 45/50\n",
      "227/512 [============>.................] - ETA: 2s - loss: 1.7549e-04 - rms: 0.0132 - mae: 0.0049"
     ]
    }
   ],
   "source": [
    "auto, encode = make_and_train_autoencoder(X, metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3af7433e",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = encode.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a6df970c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32710, 8)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "edf18cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = np.array(q)\n",
    "df = pd.DataFrame(data=q,index=None,columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b0d6115c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.216690</td>\n",
       "      <td>0.188490</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.190135</td>\n",
       "      <td>0.354213</td>\n",
       "      <td>0.440773</td>\n",
       "      <td>0.490538</td>\n",
       "      <td>0.325851</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.141760</td>\n",
       "      <td>0.381643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.342938</td>\n",
       "      <td>0.267937</td>\n",
       "      <td>0.615193</td>\n",
       "      <td>0.555364</td>\n",
       "      <td>0.535768</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.326538</td>\n",
       "      <td>0.609432</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.551288</td>\n",
       "      <td>0.413152</td>\n",
       "      <td>0.690596</td>\n",
       "      <td>0.311742</td>\n",
       "      <td>0.166114</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.292853</td>\n",
       "      <td>0.429766</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125191</td>\n",
       "      <td>0.273994</td>\n",
       "      <td>0.396629</td>\n",
       "      <td>0.382142</td>\n",
       "      <td>0.333955</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.285552</td>\n",
       "      <td>0.280533</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.136062</td>\n",
       "      <td>0.256063</td>\n",
       "      <td>0.242172</td>\n",
       "      <td>0.208914</td>\n",
       "      <td>0.263304</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32705</th>\n",
       "      <td>0.312745</td>\n",
       "      <td>0.213432</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.177604</td>\n",
       "      <td>0.211671</td>\n",
       "      <td>0.254998</td>\n",
       "      <td>0.213962</td>\n",
       "      <td>0.247138</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32706</th>\n",
       "      <td>0.248369</td>\n",
       "      <td>0.521588</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730797</td>\n",
       "      <td>0.598629</td>\n",
       "      <td>1.044003</td>\n",
       "      <td>0.386442</td>\n",
       "      <td>0.397927</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32707</th>\n",
       "      <td>0.343048</td>\n",
       "      <td>0.708353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.751305</td>\n",
       "      <td>0.673825</td>\n",
       "      <td>0.816179</td>\n",
       "      <td>0.666820</td>\n",
       "      <td>0.447209</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32708</th>\n",
       "      <td>0.374286</td>\n",
       "      <td>0.533337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.496663</td>\n",
       "      <td>0.505217</td>\n",
       "      <td>0.341860</td>\n",
       "      <td>0.231692</td>\n",
       "      <td>0.067951</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32709</th>\n",
       "      <td>0.477894</td>\n",
       "      <td>0.379285</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.290209</td>\n",
       "      <td>0.387486</td>\n",
       "      <td>0.863065</td>\n",
       "      <td>0.465184</td>\n",
       "      <td>0.502955</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32710 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1    2         3         4         5         6  \\\n",
       "0      0.216690  0.188490  0.0  0.190135  0.354213  0.440773  0.490538   \n",
       "1      0.141760  0.381643  0.0  0.342938  0.267937  0.615193  0.555364   \n",
       "2      0.326538  0.609432  0.0  0.551288  0.413152  0.690596  0.311742   \n",
       "3      0.292853  0.429766  0.0  0.125191  0.273994  0.396629  0.382142   \n",
       "4      0.285552  0.280533  0.0  0.136062  0.256063  0.242172  0.208914   \n",
       "...         ...       ...  ...       ...       ...       ...       ...   \n",
       "32705  0.312745  0.213432  0.0  0.177604  0.211671  0.254998  0.213962   \n",
       "32706  0.248369  0.521588  0.0  0.730797  0.598629  1.044003  0.386442   \n",
       "32707  0.343048  0.708353  0.0  0.751305  0.673825  0.816179  0.666820   \n",
       "32708  0.374286  0.533337  0.0  0.496663  0.505217  0.341860  0.231692   \n",
       "32709  0.477894  0.379285  0.0  0.290209  0.387486  0.863065  0.465184   \n",
       "\n",
       "              7  label  \n",
       "0      0.325851    0.0  \n",
       "1      0.535768    1.0  \n",
       "2      0.166114    0.0  \n",
       "3      0.333955    0.0  \n",
       "4      0.263304    0.0  \n",
       "...         ...    ...  \n",
       "32705  0.247138    1.0  \n",
       "32706  0.397927    1.0  \n",
       "32707  0.447209    1.0  \n",
       "32708  0.067951    1.0  \n",
       "32709  0.502955    1.0  \n",
       "\n",
       "[32710 rows x 9 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = y\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5e992240",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('training_cnn_autoencoded.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2094468f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "512/512 [==============================] - 6s 7ms/step - loss: 0.0137 - rms: 0.0863 - mae: 0.0445\n",
      "Epoch 2/50\n",
      "512/512 [==============================] - 3s 7ms/step - loss: 0.0028 - rms: 0.0526 - mae: 0.0318\n",
      "Epoch 3/50\n",
      "512/512 [==============================] - 3s 7ms/step - loss: 0.0020 - rms: 0.0447 - mae: 0.0260\n",
      "Epoch 4/50\n",
      "512/512 [==============================] - 3s 7ms/step - loss: 0.0018 - rms: 0.0429 - mae: 0.0234\n",
      "Epoch 5/50\n",
      "304/512 [================>.............] - ETA: 1s - loss: 0.0018 - rms: 0.0426 - mae: 0.0228"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [73]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining_ROS.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m X, y \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[:,:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m----> 3\u001b[0m auto, encode \u001b[38;5;241m=\u001b[39m \u001b[43mmake_and_train_autoencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMETRICS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m q \u001b[38;5;241m=\u001b[39m encode\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[0;32m      5\u001b[0m w \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(q)\n",
      "Input \u001b[1;32mIn [55]\u001b[0m, in \u001b[0;36mmake_and_train_autoencoder\u001b[1;34m(X_train, metrics)\u001b[0m\n\u001b[0;32m     13\u001b[0m autoencoder \u001b[38;5;241m=\u001b[39m Model(inputs\u001b[38;5;241m=\u001b[39minput_, outputs\u001b[38;5;241m=\u001b[39moutput)\n\u001b[0;32m     14\u001b[0m autoencoder\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     15\u001b[0m                     metrics\u001b[38;5;241m=\u001b[39m[metrics])\n\u001b[1;32m---> 16\u001b[0m \u001b[43mautoencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m                \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m                \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m#Use only the encoder part for dimensionality reduction\u001b[39;00m\n\u001b[0;32m     20\u001b[0m encoder \u001b[38;5;241m=\u001b[39m Model(inputs\u001b[38;5;241m=\u001b[39minput_, outputs\u001b[38;5;241m=\u001b[39mbottleneck)\n",
      "File \u001b[1;32mc:\\users\\thoma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\users\\thoma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\users\\thoma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\users\\thoma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\users\\thoma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\users\\thoma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2954\u001b[0m   (graph_function,\n\u001b[0;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\thoma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1856\u001b[0m     args,\n\u001b[0;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1858\u001b[0m     executing_eagerly)\n\u001b[0;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\users\\thoma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\users\\thoma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#### CNN autoencode\n",
    "df = pd.read_csv('training_CNN.csv')\n",
    "X, y = df.iloc[:,:-1], df.iloc[:, -1]\n",
    "auto, encode = make_and_train_autoencoder(X, metrics=METRICS)\n",
    "q = encode.predict(X)\n",
    "w = np.array(q)\n",
    "df = pd.DataFrame(data=w,index=None,columns=None)\n",
    "df['label'] = y\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a725534",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
