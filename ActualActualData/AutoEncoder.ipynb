{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cd6a5fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras import metrics, Input\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "de00d39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [metrics.RootMeanSquaredError(name='rms'), metrics.MeanAbsoluteError(name='mae')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f400e947",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODING_DIM = 16 #Desired Dimension\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5d0b0a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_and_train_autoencoder(X_train, metrics=METRICS):\n",
    "    \n",
    "    len_input_output = X_train.shape[-1]\n",
    "    input_ = Input(shape=(len_input_output,))\n",
    "    encoded = Dense(units=ENCODING_DIM*2, activation=\"relu\")(input_)\n",
    "    bottleneck = Dense(units=ENCODING_DIM, \n",
    "                       activation=\"relu\")(encoded)\n",
    "    decoded = Dense(units=ENCODING_DIM*2, \n",
    "                    activation=\"relu\")(bottleneck)\n",
    "    output = Dense(units=len_input_output, \n",
    "                    activation=\"linear\")(decoded)\n",
    "    #Training is performed on the entire autoencoder\n",
    "    autoencoder = Model(inputs=input_, outputs=output)\n",
    "    autoencoder.compile(optimizer='adam', loss='mean_squared_error',\n",
    "                        metrics=[metrics])\n",
    "    autoencoder.fit(X_train, X_train,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS)\n",
    "    #Use only the encoder part for dimensionality reduction\n",
    "    encoder = Model(inputs=input_, outputs=bottleneck)\n",
    "    return autoencoder, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7645c249",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('training_ROS.csv')\n",
    "qw = pd.read_csv('validation_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e8572068",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.iloc[:,:-1], df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "52c2463a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8178/8178 [==============================] - 59s 7ms/step - loss: 0.0015 - rms: 0.0389 - mae: 0.0186\n",
      "Epoch 2/50\n",
      "8178/8178 [==============================] - 52s 6ms/step - loss: 3.4841e-04 - rms: 0.0187 - mae: 0.0090\n",
      "Epoch 3/50\n",
      "8178/8178 [==============================] - 52s 6ms/step - loss: 3.3358e-04 - rms: 0.0183 - mae: 0.0087\n",
      "Epoch 4/50\n",
      "8178/8178 [==============================] - 53s 6ms/step - loss: 3.2797e-04 - rms: 0.0181 - mae: 0.0085\n",
      "Epoch 5/50\n",
      "8178/8178 [==============================] - 52s 6ms/step - loss: 3.2459e-04 - rms: 0.0180 - mae: 0.0083\n",
      "Epoch 6/50\n",
      "8178/8178 [==============================] - 53s 6ms/step - loss: 3.2171e-04 - rms: 0.0179 - mae: 0.0082\n",
      "Epoch 7/50\n",
      "8178/8178 [==============================] - 53s 6ms/step - loss: 3.1976e-04 - rms: 0.0179 - mae: 0.0081\n",
      "Epoch 8/50\n",
      "8178/8178 [==============================] - 52s 6ms/step - loss: 3.1761e-04 - rms: 0.0178 - mae: 0.0080\n",
      "Epoch 9/50\n",
      "8178/8178 [==============================] - 53s 6ms/step - loss: 3.1685e-04 - rms: 0.0178 - mae: 0.0080\n",
      "Epoch 10/50\n",
      "8178/8178 [==============================] - 53s 6ms/step - loss: 3.1567e-04 - rms: 0.0178 - mae: 0.0080\n",
      "Epoch 11/50\n",
      "8178/8178 [==============================] - 57s 7ms/step - loss: 3.1476e-04 - rms: 0.0177 - mae: 0.0079\n",
      "Epoch 12/50\n",
      "8178/8178 [==============================] - 45s 6ms/step - loss: 3.1438e-04 - rms: 0.0177 - mae: 0.0079\n",
      "Epoch 13/50\n",
      "8178/8178 [==============================] - 53s 6ms/step - loss: 3.1385e-04 - rms: 0.0177 - mae: 0.0078\n",
      "Epoch 14/50\n",
      "8178/8178 [==============================] - 53s 6ms/step - loss: 3.1402e-04 - rms: 0.0177 - mae: 0.0079\n",
      "Epoch 15/50\n",
      "8178/8178 [==============================] - 55s 7ms/step - loss: 3.1336e-04 - rms: 0.0177 - mae: 0.0078\n",
      "Epoch 16/50\n",
      "8178/8178 [==============================] - 54s 7ms/step - loss: 3.1254e-04 - rms: 0.0177 - mae: 0.0078\n",
      "Epoch 17/50\n",
      "8178/8178 [==============================] - 56s 7ms/step - loss: 3.1181e-04 - rms: 0.0177 - mae: 0.0078\n",
      "Epoch 18/50\n",
      "8178/8178 [==============================] - 55s 7ms/step - loss: 3.1139e-04 - rms: 0.0176 - mae: 0.0078\n",
      "Epoch 19/50\n",
      "8178/8178 [==============================] - 55s 7ms/step - loss: 3.1043e-04 - rms: 0.0176 - mae: 0.0077\n",
      "Epoch 20/50\n",
      "8178/8178 [==============================] - 55s 7ms/step - loss: 3.0782e-04 - rms: 0.0175 - mae: 0.0078\n",
      "Epoch 21/50\n",
      "8178/8178 [==============================] - 54s 7ms/step - loss: 3.0656e-04 - rms: 0.0175 - mae: 0.0078\n",
      "Epoch 22/50\n",
      "8178/8178 [==============================] - 53s 7ms/step - loss: 3.0608e-04 - rms: 0.0175 - mae: 0.0078\n",
      "Epoch 23/50\n",
      "8178/8178 [==============================] - 54s 7ms/step - loss: 3.0478e-04 - rms: 0.0175 - mae: 0.0078\n",
      "Epoch 24/50\n",
      "8178/8178 [==============================] - 54s 7ms/step - loss: 3.0425e-04 - rms: 0.0174 - mae: 0.0077\n",
      "Epoch 25/50\n",
      "8178/8178 [==============================] - 55s 7ms/step - loss: 3.0015e-04 - rms: 0.0173 - mae: 0.0077\n",
      "Epoch 26/50\n",
      "8178/8178 [==============================] - 54s 7ms/step - loss: 2.9844e-04 - rms: 0.0173 - mae: 0.0077\n",
      "Epoch 27/50\n",
      "8178/8178 [==============================] - 53s 7ms/step - loss: 2.9643e-04 - rms: 0.0172 - mae: 0.0076\n",
      "Epoch 28/50\n",
      "8178/8178 [==============================] - 53s 7ms/step - loss: 2.9591e-04 - rms: 0.0172 - mae: 0.0076\n",
      "Epoch 29/50\n",
      "8178/8178 [==============================] - 55s 7ms/step - loss: 2.9567e-04 - rms: 0.0172 - mae: 0.0076\n",
      "Epoch 30/50\n",
      "8178/8178 [==============================] - 59s 7ms/step - loss: 2.9600e-04 - rms: 0.0172 - mae: 0.0076\n",
      "Epoch 31/50\n",
      "8178/8178 [==============================] - 52s 6ms/step - loss: 2.9493e-04 - rms: 0.0172 - mae: 0.0076\n",
      "Epoch 32/50\n",
      "8178/8178 [==============================] - 53s 6ms/step - loss: 2.9497e-04 - rms: 0.0172 - mae: 0.0076\n",
      "Epoch 33/50\n",
      "8178/8178 [==============================] - 52s 6ms/step - loss: 2.9542e-04 - rms: 0.0172 - mae: 0.0076\n",
      "Epoch 34/50\n",
      "8178/8178 [==============================] - 54s 7ms/step - loss: 2.9418e-04 - rms: 0.0172 - mae: 0.0075\n",
      "Epoch 35/50\n",
      "8178/8178 [==============================] - 57s 7ms/step - loss: 2.9529e-04 - rms: 0.0172 - mae: 0.0076\n",
      "Epoch 36/50\n",
      "8178/8178 [==============================] - 54s 7ms/step - loss: 2.9532e-04 - rms: 0.0172 - mae: 0.0076\n",
      "Epoch 37/50\n",
      "8178/8178 [==============================] - 55s 7ms/step - loss: 2.9505e-04 - rms: 0.0172 - mae: 0.0076\n",
      "Epoch 38/50\n",
      "8178/8178 [==============================] - 53s 7ms/step - loss: 2.9539e-04 - rms: 0.0172 - mae: 0.0076\n",
      "Epoch 39/50\n",
      "8178/8178 [==============================] - 54s 7ms/step - loss: 2.9521e-04 - rms: 0.0172 - mae: 0.0076\n",
      "Epoch 40/50\n",
      "8178/8178 [==============================] - 55s 7ms/step - loss: 2.9340e-04 - rms: 0.0171 - mae: 0.0075\n",
      "Epoch 41/50\n",
      "8178/8178 [==============================] - 54s 7ms/step - loss: 2.9412e-04 - rms: 0.0172 - mae: 0.0075\n",
      "Epoch 42/50\n",
      "8178/8178 [==============================] - 53s 7ms/step - loss: 2.9395e-04 - rms: 0.0171 - mae: 0.0075\n",
      "Epoch 43/50\n",
      "8178/8178 [==============================] - 53s 7ms/step - loss: 2.9381e-04 - rms: 0.0171 - mae: 0.0075\n",
      "Epoch 44/50\n",
      "8178/8178 [==============================] - 54s 7ms/step - loss: 2.9411e-04 - rms: 0.0171 - mae: 0.0075\n",
      "Epoch 45/50\n",
      "8178/8178 [==============================] - 54s 7ms/step - loss: 2.9449e-04 - rms: 0.0172 - mae: 0.0075\n",
      "Epoch 46/50\n",
      "8178/8178 [==============================] - 61s 7ms/step - loss: 2.9398e-04 - rms: 0.0171 - mae: 0.0075\n",
      "Epoch 47/50\n",
      "8178/8178 [==============================] - 62s 8ms/step - loss: 2.9375e-04 - rms: 0.0171 - mae: 0.0075\n",
      "Epoch 48/50\n",
      "8178/8178 [==============================] - 63s 8ms/step - loss: 2.9383e-04 - rms: 0.0171 - mae: 0.0075\n",
      "Epoch 49/50\n",
      "8178/8178 [==============================] - 58s 7ms/step - loss: 2.9380e-04 - rms: 0.0171 - mae: 0.0075\n",
      "Epoch 50/50\n",
      "8178/8178 [==============================] - 55s 7ms/step - loss: 2.9276e-04 - rms: 0.0171 - mae: 0.0075\n"
     ]
    }
   ],
   "source": [
    "auto, encode = make_and_train_autoencoder(X, metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "821cdcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = encode.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "574e4d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32710, 16)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "40f7c6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = np.array(q)\n",
    "df = pd.DataFrame(data=q,index=None,columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "71dace4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.176377</td>\n",
       "      <td>0.297052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.168536</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.091217</td>\n",
       "      <td>0.177422</td>\n",
       "      <td>0.192657</td>\n",
       "      <td>0.114414</td>\n",
       "      <td>0.042181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.303161</td>\n",
       "      <td>0.158141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.164332</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.145195</td>\n",
       "      <td>0.334893</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.130104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.108132</td>\n",
       "      <td>0.276668</td>\n",
       "      <td>0.220707</td>\n",
       "      <td>0.228691</td>\n",
       "      <td>0.136393</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.342791</td>\n",
       "      <td>0.180877</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.196175</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.315034</td>\n",
       "      <td>0.246673</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.349820</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.284155</td>\n",
       "      <td>0.224775</td>\n",
       "      <td>0.130678</td>\n",
       "      <td>0.121905</td>\n",
       "      <td>0.173306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.310383</td>\n",
       "      <td>0.088846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.401038</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.155673</td>\n",
       "      <td>0.372546</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.313895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250187</td>\n",
       "      <td>0.228466</td>\n",
       "      <td>0.118142</td>\n",
       "      <td>0.129902</td>\n",
       "      <td>0.078225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400816</td>\n",
       "      <td>0.140651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.108406</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.178996</td>\n",
       "      <td>0.244286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225383</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.261496</td>\n",
       "      <td>0.113891</td>\n",
       "      <td>0.078897</td>\n",
       "      <td>0.074989</td>\n",
       "      <td>0.069801</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.212734</td>\n",
       "      <td>0.120407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058746</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32705</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200497</td>\n",
       "      <td>0.121754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.119313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.280635</td>\n",
       "      <td>0.120347</td>\n",
       "      <td>0.068865</td>\n",
       "      <td>0.063566</td>\n",
       "      <td>0.045507</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.094394</td>\n",
       "      <td>0.161756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071938</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32706</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.354684</td>\n",
       "      <td>0.316169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.300437</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.122386</td>\n",
       "      <td>0.171823</td>\n",
       "      <td>0.259745</td>\n",
       "      <td>0.170999</td>\n",
       "      <td>0.209344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.518709</td>\n",
       "      <td>0.172038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.485416</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32707</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.331742</td>\n",
       "      <td>0.354997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.313935</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.091947</td>\n",
       "      <td>0.291601</td>\n",
       "      <td>0.205047</td>\n",
       "      <td>0.139764</td>\n",
       "      <td>0.199323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.289754</td>\n",
       "      <td>0.222683</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.496981</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32708</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.324100</td>\n",
       "      <td>0.248483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.334480</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.270242</td>\n",
       "      <td>0.115537</td>\n",
       "      <td>0.002554</td>\n",
       "      <td>0.023827</td>\n",
       "      <td>0.143548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.096559</td>\n",
       "      <td>0.086054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.354157</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32709</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.281842</td>\n",
       "      <td>0.359974</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.265191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.272565</td>\n",
       "      <td>0.228868</td>\n",
       "      <td>0.272089</td>\n",
       "      <td>0.175516</td>\n",
       "      <td>0.035595</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.597491</td>\n",
       "      <td>0.286307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.183078</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32710 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2    3         4    5         6         7  \\\n",
       "0      0.0  0.176377  0.297052  0.0  0.168536  0.0  0.091217  0.177422   \n",
       "1      0.0  0.145195  0.334893  0.0  0.130104  0.0  0.108132  0.276668   \n",
       "2      0.0  0.315034  0.246673  0.0  0.349820  0.0  0.284155  0.224775   \n",
       "3      0.0  0.155673  0.372546  0.0  0.313895  0.0  0.250187  0.228466   \n",
       "4      0.0  0.178996  0.244286  0.0  0.225383  0.0  0.261496  0.113891   \n",
       "...    ...       ...       ...  ...       ...  ...       ...       ...   \n",
       "32705  0.0  0.200497  0.121754  0.0  0.119313  0.0  0.280635  0.120347   \n",
       "32706  0.0  0.354684  0.316169  0.0  0.300437  0.0  0.122386  0.171823   \n",
       "32707  0.0  0.331742  0.354997  0.0  0.313935  0.0  0.091947  0.291601   \n",
       "32708  0.0  0.324100  0.248483  0.0  0.334480  0.0  0.270242  0.115537   \n",
       "32709  0.0  0.281842  0.359974  0.0  0.265191  0.0  0.272565  0.228868   \n",
       "\n",
       "              8         9        10   11        12        13   14        15  \\\n",
       "0      0.192657  0.114414  0.042181  0.0  0.303161  0.158141  0.0  0.164332   \n",
       "1      0.220707  0.228691  0.136393  0.0  0.342791  0.180877  0.0  0.196175   \n",
       "2      0.130678  0.121905  0.173306  0.0  0.310383  0.088846  0.0  0.401038   \n",
       "3      0.118142  0.129902  0.078225  0.0  0.400816  0.140651  0.0  0.108406   \n",
       "4      0.078897  0.074989  0.069801  0.0  0.212734  0.120407  0.0  0.058746   \n",
       "...         ...       ...       ...  ...       ...       ...  ...       ...   \n",
       "32705  0.068865  0.063566  0.045507  0.0  0.094394  0.161756  0.0  0.071938   \n",
       "32706  0.259745  0.170999  0.209344  0.0  0.518709  0.172038  0.0  0.485416   \n",
       "32707  0.205047  0.139764  0.199323  0.0  0.289754  0.222683  0.0  0.496981   \n",
       "32708  0.002554  0.023827  0.143548  0.0  0.096559  0.086054  0.0  0.354157   \n",
       "32709  0.272089  0.175516  0.035595  0.0  0.597491  0.286307  0.0  0.183078   \n",
       "\n",
       "       label  \n",
       "0        0.0  \n",
       "1        1.0  \n",
       "2        0.0  \n",
       "3        0.0  \n",
       "4        0.0  \n",
       "...      ...  \n",
       "32705    1.0  \n",
       "32706    1.0  \n",
       "32707    1.0  \n",
       "32708    1.0  \n",
       "32709    1.0  \n",
       "\n",
       "[32710 rows x 17 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = y\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "63fa690e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('training_ros_autoencoded_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f65c7f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2496/2496 [==============================] - 19s 7ms/step - loss: 0.0035 - rms: 0.0324 - mae: 0.0131\n",
      "Epoch 2/50\n",
      "2496/2496 [==============================] - 14s 6ms/step - loss: 4.0909e-04 - rms: 0.0202 - mae: 0.0113\n",
      "Epoch 3/50\n",
      "2496/2496 [==============================] - 14s 6ms/step - loss: 2.7897e-04 - rms: 0.0167 - mae: 0.0089\n",
      "Epoch 4/50\n",
      "2496/2496 [==============================] - 17s 7ms/step - loss: 2.0577e-04 - rms: 0.0143 - mae: 0.0070\n",
      "Epoch 5/50\n",
      "2496/2496 [==============================] - 15s 6ms/step - loss: 1.8467e-04 - rms: 0.0136 - mae: 0.0062\n",
      "Epoch 6/50\n",
      "2496/2496 [==============================] - 16s 6ms/step - loss: 1.6547e-04 - rms: 0.0129 - mae: 0.0060\n",
      "Epoch 7/50\n",
      "2496/2496 [==============================] - 17s 7ms/step - loss: 1.3380e-04 - rms: 0.0116 - mae: 0.0054\n",
      "Epoch 8/50\n",
      "2496/2496 [==============================] - 18s 7ms/step - loss: 1.2926e-04 - rms: 0.0114 - mae: 0.0054\n",
      "Epoch 9/50\n",
      "2496/2496 [==============================] - 16s 6ms/step - loss: 1.2687e-04 - rms: 0.0113 - mae: 0.0052\n",
      "Epoch 10/50\n",
      "2496/2496 [==============================] - 21s 8ms/step - loss: 1.2519e-04 - rms: 0.0112 - mae: 0.0052\n",
      "Epoch 11/50\n",
      "2496/2496 [==============================] - 22s 9ms/step - loss: 1.2688e-04 - rms: 0.0113 - mae: 0.0052\n",
      "Epoch 12/50\n",
      "2496/2496 [==============================] - 15s 6ms/step - loss: 1.2342e-04 - rms: 0.0111 - mae: 0.0050\n",
      "Epoch 13/50\n",
      "2496/2496 [==============================] - 20s 8ms/step - loss: 1.2303e-04 - rms: 0.0111 - mae: 0.0051\n",
      "Epoch 14/50\n",
      "2496/2496 [==============================] - 14s 6ms/step - loss: 1.2389e-04 - rms: 0.0111 - mae: 0.0051\n",
      "Epoch 15/50\n",
      "2496/2496 [==============================] - 14s 5ms/step - loss: 1.2280e-04 - rms: 0.0111 - mae: 0.0050\n",
      "Epoch 16/50\n",
      "2496/2496 [==============================] - 15s 6ms/step - loss: 1.2211e-04 - rms: 0.0111 - mae: 0.0050\n",
      "Epoch 17/50\n",
      "2496/2496 [==============================] - 14s 6ms/step - loss: 1.2175e-04 - rms: 0.0110 - mae: 0.0050\n",
      "Epoch 18/50\n",
      "2496/2496 [==============================] - 17s 7ms/step - loss: 1.2114e-04 - rms: 0.0110 - mae: 0.0049\n",
      "Epoch 19/50\n",
      "2496/2496 [==============================] - 14s 6ms/step - loss: 1.1982e-04 - rms: 0.0109 - mae: 0.0048\n",
      "Epoch 20/50\n",
      "2496/2496 [==============================] - 14s 5ms/step - loss: 1.2148e-04 - rms: 0.0110 - mae: 0.0049\n",
      "Epoch 21/50\n",
      "2496/2496 [==============================] - 14s 6ms/step - loss: 1.1742e-04 - rms: 0.0108 - mae: 0.0047\n",
      "Epoch 22/50\n",
      "2496/2496 [==============================] - 14s 5ms/step - loss: 1.1957e-04 - rms: 0.0109 - mae: 0.0048\n",
      "Epoch 23/50\n",
      "2496/2496 [==============================] - 16s 6ms/step - loss: 1.2113e-04 - rms: 0.0110 - mae: 0.0049\n",
      "Epoch 24/50\n",
      "2496/2496 [==============================] - 16s 6ms/step - loss: 1.1795e-04 - rms: 0.0109 - mae: 0.0047\n",
      "Epoch 25/50\n",
      "2496/2496 [==============================] - 16s 6ms/step - loss: 1.1827e-04 - rms: 0.0109 - mae: 0.0048\n",
      "Epoch 26/50\n",
      "2496/2496 [==============================] - 16s 6ms/step - loss: 1.1844e-04 - rms: 0.0109 - mae: 0.0048\n",
      "Epoch 27/50\n",
      "2496/2496 [==============================] - 16s 6ms/step - loss: 1.1780e-04 - rms: 0.0109 - mae: 0.0047\n",
      "Epoch 28/50\n",
      "2496/2496 [==============================] - 19s 8ms/step - loss: 1.1786e-04 - rms: 0.0109 - mae: 0.0047\n",
      "Epoch 29/50\n",
      "2496/2496 [==============================] - 16s 7ms/step - loss: 1.1699e-04 - rms: 0.0108 - mae: 0.0046\n",
      "Epoch 30/50\n",
      "2496/2496 [==============================] - 16s 6ms/step - loss: 1.1677e-04 - rms: 0.0108 - mae: 0.0047\n",
      "Epoch 31/50\n",
      "2496/2496 [==============================] - 16s 6ms/step - loss: 1.1818e-04 - rms: 0.0109 - mae: 0.0048\n",
      "Epoch 32/50\n",
      "2496/2496 [==============================] - 16s 6ms/step - loss: 1.1734e-04 - rms: 0.0108 - mae: 0.0047\n",
      "Epoch 33/50\n",
      "2496/2496 [==============================] - 17s 7ms/step - loss: 1.1856e-04 - rms: 0.0109 - mae: 0.0047\n",
      "Epoch 34/50\n",
      "2496/2496 [==============================] - 16s 6ms/step - loss: 1.1665e-04 - rms: 0.0108 - mae: 0.0046\n",
      "Epoch 35/50\n",
      "2496/2496 [==============================] - 16s 6ms/step - loss: 1.1651e-04 - rms: 0.0108 - mae: 0.0046\n",
      "Epoch 36/50\n",
      "2496/2496 [==============================] - 16s 7ms/step - loss: 1.1769e-04 - rms: 0.0108 - mae: 0.0047\n",
      "Epoch 37/50\n",
      "2496/2496 [==============================] - 16s 6ms/step - loss: 1.1864e-04 - rms: 0.0109 - mae: 0.0047\n",
      "Epoch 38/50\n",
      "2496/2496 [==============================] - 16s 6ms/step - loss: 1.1490e-04 - rms: 0.0107 - mae: 0.0045\n",
      "Epoch 39/50\n",
      "2496/2496 [==============================] - 16s 7ms/step - loss: 1.1640e-04 - rms: 0.0108 - mae: 0.0046\n",
      "Epoch 40/50\n",
      "2496/2496 [==============================] - 16s 7ms/step - loss: 1.1586e-04 - rms: 0.0108 - mae: 0.0046\n",
      "Epoch 41/50\n",
      "2496/2496 [==============================] - 16s 6ms/step - loss: 1.1564e-04 - rms: 0.0108 - mae: 0.0046\n",
      "Epoch 42/50\n",
      "2496/2496 [==============================] - 16s 6ms/step - loss: 1.1747e-04 - rms: 0.0108 - mae: 0.0047\n",
      "Epoch 43/50\n",
      "2496/2496 [==============================] - 16s 7ms/step - loss: 1.1625e-04 - rms: 0.0108 - mae: 0.0046\n",
      "Epoch 44/50\n",
      "2496/2496 [==============================] - 16s 6ms/step - loss: 1.1573e-04 - rms: 0.0108 - mae: 0.0046\n",
      "Epoch 45/50\n",
      "2496/2496 [==============================] - 16s 6ms/step - loss: 1.1506e-04 - rms: 0.0107 - mae: 0.0046\n",
      "Epoch 46/50\n",
      "2496/2496 [==============================] - 17s 7ms/step - loss: 1.1592e-04 - rms: 0.0108 - mae: 0.0046\n",
      "Epoch 47/50\n",
      "2496/2496 [==============================] - 16s 7ms/step - loss: 1.1589e-04 - rms: 0.0108 - mae: 0.0046\n",
      "Epoch 48/50\n",
      "2496/2496 [==============================] - 16s 6ms/step - loss: 1.1624e-04 - rms: 0.0108 - mae: 0.0046\n",
      "Epoch 49/50\n",
      "2496/2496 [==============================] - 16s 6ms/step - loss: 1.1714e-04 - rms: 0.0108 - mae: 0.0046\n",
      "Epoch 50/50\n",
      "2496/2496 [==============================] - 17s 7ms/step - loss: 1.1356e-04 - rms: 0.0107 - mae: 0.0044\n"
     ]
    }
   ],
   "source": [
    "#### CNN autoencode\n",
    "df = pd.read_csv('training_CNN.csv')\n",
    "X, y = df.iloc[:,:-1], df.iloc[:, -1]\n",
    "auto, encode = make_and_train_autoencoder(X, metrics=METRICS)\n",
    "q = encode.predict(X)\n",
    "w = np.array(q)\n",
    "df = pd.DataFrame(data=w,index=None,columns=None)\n",
    "df['label'] = y\n",
    "df.to_csv('training_cnn_autoencoded_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4044e3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### CNN autoencode\n",
    "df = pd.read_csv('training_RUS.csv')\n",
    "X, y = df.iloc[:,:-1], df.iloc[:, -1]\n",
    "auto, encode = make_and_train_autoencoder(X, metrics=METRICS)\n",
    "q = encode.predict(X)\n",
    "w = np.array(q)\n",
    "df = pd.DataFrame(data=w,index=None,columns=None)\n",
    "df['label'] = y\n",
    "df.to_csv('training_rus_autoencoded_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b769c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### CNN autoencode\n",
    "df = pd.read_csv('training_smote.csv')\n",
    "X, y = df.iloc[:,:-1], df.iloc[:, -1]\n",
    "auto, encode = make_and_train_autoencoder(X, metrics=METRICS)\n",
    "q = encode.predict(X)\n",
    "w = np.array(q)\n",
    "df = pd.DataFrame(data=w,index=None,columns=None)\n",
    "df['label'] = y\n",
    "df.to_csv('training_smote_autoencoded_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f572f659",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
