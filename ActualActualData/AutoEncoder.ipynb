{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ef6f1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras import metrics, Input\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "880006ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [metrics.RootMeanSquaredError(name='rms'), metrics.MeanAbsoluteError(name='mae')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c842601a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODING_DIM = 16 #Desired Dimension\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dfa798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_and_train_autoencoder(X_train, metrics=METRICS):\n",
    "    \n",
    "    len_input_output = X_train.shape[-1]\n",
    "    input_ = Input(shape=(len_input_output,))\n",
    "    encoded = Dense(units=ENCODING_DIM*2, activation=\"relu\")(input_)\n",
    "    bottleneck = Dense(units=ENCODING_DIM, \n",
    "                       activation=\"relu\")(encoded)\n",
    "    decoded = Dense(units=ENCODING_DIM*2, \n",
    "                    activation=\"relu\")(bottleneck)\n",
    "    output = Dense(units=len_input_output, \n",
    "                    activation=\"linear\")(decoded)\n",
    "    #Training is performed on the entire autoencoder\n",
    "    autoencoder = Model(inputs=input_, outputs=output)\n",
    "    autoencoder.compile(optimizer='adam', loss='mean_squared_error',\n",
    "                        metrics=[metrics])\n",
    "    autoencoder.fit(X_train, X_train,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS)\n",
    "    #Use only the encoder part for dimensionality reduction\n",
    "    encoder = Model(inputs=input_, outputs=bottleneck)\n",
    "    return autoencoder, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eeed2b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "512/512 [==============================] - 5s 6ms/step - loss: 0.0062 - rms: 0.0791 - mae: 0.0442\n",
      "Epoch 2/50\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 7.0115e-04 - rms: 0.0265 - mae: 0.0157\n",
      "Epoch 3/50\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 3.4643e-04 - rms: 0.0186 - mae: 0.0097\n",
      "Epoch 4/50\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 2.6384e-04 - rms: 0.0162 - mae: 0.0080\n",
      "Epoch 5/50\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 2.1815e-04 - rms: 0.0148 - mae: 0.0070\n",
      "Epoch 6/50\n",
      "512/512 [==============================] - 3s 7ms/step - loss: 1.7448e-04 - rms: 0.0132 - mae: 0.0060\n",
      "Epoch 7/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 1.4272e-04 - rms: 0.0119 - mae: 0.0052\n",
      "Epoch 8/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 1.2957e-04 - rms: 0.0114 - mae: 0.0047\n",
      "Epoch 9/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 1.2512e-04 - rms: 0.0112 - mae: 0.0046\n",
      "Epoch 10/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 1.2255e-04 - rms: 0.0111 - mae: 0.0044\n",
      "Epoch 11/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 1.2216e-04 - rms: 0.0111 - mae: 0.0045\n",
      "Epoch 12/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 1.1985e-04 - rms: 0.0109 - mae: 0.0043\n",
      "Epoch 13/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 1.1935e-04 - rms: 0.0109 - mae: 0.0043\n",
      "Epoch 14/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 1.1974e-04 - rms: 0.0109 - mae: 0.0043\n",
      "Epoch 15/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 1.1828e-04 - rms: 0.0109 - mae: 0.0042\n",
      "Epoch 16/50\n",
      "512/512 [==============================] - 3s 6ms/step - loss: 1.1795e-04 - rms: 0.0109 - mae: 0.0042\n",
      "Epoch 17/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 1.1792e-04 - rms: 0.0109 - mae: 0.0042\n",
      "Epoch 18/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 1.1740e-04 - rms: 0.0108 - mae: 0.0042\n",
      "Epoch 19/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 1.1648e-04 - rms: 0.0108 - mae: 0.0041\n",
      "Epoch 20/50\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 1.1679e-04 - rms: 0.0108 - mae: 0.0041\n",
      "Epoch 21/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 1.1620e-04 - rms: 0.0108 - mae: 0.0041\n",
      "Epoch 22/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 1.1617e-04 - rms: 0.0108 - mae: 0.0040\n",
      "Epoch 23/50\n",
      "512/512 [==============================] - 3s 6ms/step - loss: 1.1690e-04 - rms: 0.0108 - mae: 0.0041\n",
      "Epoch 24/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 1.1553e-04 - rms: 0.0107 - mae: 0.0040\n",
      "Epoch 25/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 1.1603e-04 - rms: 0.0108 - mae: 0.0040\n",
      "Epoch 26/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 1.1559e-04 - rms: 0.0108 - mae: 0.0040\n",
      "Epoch 27/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 1.1556e-04 - rms: 0.0107 - mae: 0.0040\n",
      "Epoch 28/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 1.1528e-04 - rms: 0.0107 - mae: 0.0039\n",
      "Epoch 29/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 1.1602e-04 - rms: 0.0108 - mae: 0.0040\n",
      "Epoch 30/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 1.1552e-04 - rms: 0.0107 - mae: 0.0039\n",
      "Epoch 31/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 1.1557e-04 - rms: 0.0108 - mae: 0.0039\n",
      "Epoch 32/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 1.1537e-04 - rms: 0.0107 - mae: 0.0040\n",
      "Epoch 33/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 1.1538e-04 - rms: 0.0107 - mae: 0.0039\n",
      "Epoch 34/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 1.1609e-04 - rms: 0.0108 - mae: 0.0040\n",
      "Epoch 35/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 1.1522e-04 - rms: 0.0107 - mae: 0.0039\n",
      "Epoch 36/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 1.1493e-04 - rms: 0.0107 - mae: 0.0039\n",
      "Epoch 37/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 1.1572e-04 - rms: 0.0108 - mae: 0.0039\n",
      "Epoch 38/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 1.1584e-04 - rms: 0.0108 - mae: 0.0040\n",
      "Epoch 39/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 1.1464e-04 - rms: 0.0107 - mae: 0.0038\n",
      "Epoch 40/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 1.1551e-04 - rms: 0.0107 - mae: 0.0039\n",
      "Epoch 41/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 1.1477e-04 - rms: 0.0107 - mae: 0.0038\n",
      "Epoch 42/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 1.1496e-04 - rms: 0.0107 - mae: 0.0039\n",
      "Epoch 43/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 1.1499e-04 - rms: 0.0107 - mae: 0.0039\n",
      "Epoch 44/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 1.1502e-04 - rms: 0.0107 - mae: 0.0039\n",
      "Epoch 45/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 1.1464e-04 - rms: 0.0107 - mae: 0.0038\n",
      "Epoch 46/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 1.1485e-04 - rms: 0.0107 - mae: 0.0039\n",
      "Epoch 47/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 1.1421e-04 - rms: 0.0107 - mae: 0.0038\n",
      "Epoch 48/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 1.1496e-04 - rms: 0.0107 - mae: 0.0039\n",
      "Epoch 49/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 1.1490e-04 - rms: 0.0107 - mae: 0.0039\n",
      "Epoch 50/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 1.1407e-04 - rms: 0.0107 - mae: 0.0038\n"
     ]
    }
   ],
   "source": [
    "#### ROS autoencode\n",
    "df = pd.read_csv('training_ros.csv')\n",
    "X, y = df.iloc[:,:-1], df.iloc[:, -1]\n",
    "auto, encode = make_and_train_autoencoder(X, metrics=METRICS)\n",
    "q = encode.predict(X)\n",
    "w = np.array(q)\n",
    "df = pd.DataFrame(data=w,index=None,columns=None)\n",
    "df['label'] = y\n",
    "df.to_csv('training_ros_autoencoded_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58d64744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "156/156 [==============================] - 2s 5ms/step - loss: 0.0137 - rms: 0.0574 - mae: 0.0212\n",
      "Epoch 2/50\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 0.0029 - rms: 0.0541 - mae: 0.0365\n",
      "Epoch 3/50\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 0.0015 - rms: 0.0385 - mae: 0.0254\n",
      "Epoch 4/50\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 8.6636e-04 - rms: 0.0294 - mae: 0.0188\n",
      "Epoch 5/50\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 5.7595e-04 - rms: 0.0240 - mae: 0.0146\n",
      "Epoch 6/50\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 4.2699e-04 - rms: 0.0207 - mae: 0.0120\n",
      "Epoch 7/50\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 3.5050e-04 - rms: 0.0187 - mae: 0.0103\n",
      "Epoch 8/50\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 3.0790e-04 - rms: 0.0175 - mae: 0.0093\n",
      "Epoch 9/50\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 2.7806e-04 - rms: 0.0167 - mae: 0.0085\n",
      "Epoch 10/50\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 2.5665e-04 - rms: 0.0160 - mae: 0.0080\n",
      "Epoch 11/50\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 2.3889e-04 - rms: 0.0155 - mae: 0.0075\n",
      "Epoch 12/50\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 2.2678e-04 - rms: 0.0151 - mae: 0.0073\n",
      "Epoch 13/50\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 2.1512e-04 - rms: 0.0147 - mae: 0.0070\n",
      "Epoch 14/50\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 2.0341e-04 - rms: 0.0143 - mae: 0.0066\n",
      "Epoch 15/50\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 1.9410e-04 - rms: 0.0139 - mae: 0.0062\n",
      "Epoch 16/50\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 1.8844e-04 - rms: 0.0137 - mae: 0.0061\n",
      "Epoch 17/50\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 1.8236e-04 - rms: 0.0135 - mae: 0.0059\n",
      "Epoch 18/50\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 1.7495e-04 - rms: 0.0132 - mae: 0.0055\n",
      "Epoch 19/50\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 1.7323e-04 - rms: 0.0132 - mae: 0.0055\n",
      "Epoch 20/50\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 1.6788e-04 - rms: 0.0130 - mae: 0.0053\n",
      "Epoch 21/50\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 1.6574e-04 - rms: 0.0129 - mae: 0.0051\n",
      "Epoch 22/50\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 1.6404e-04 - rms: 0.0128 - mae: 0.0051\n",
      "Epoch 23/50\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 1.6039e-04 - rms: 0.0127 - mae: 0.0049\n",
      "Epoch 24/50\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 1.5908e-04 - rms: 0.0126 - mae: 0.0049\n",
      "Epoch 25/50\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 1.5778e-04 - rms: 0.0126 - mae: 0.0048\n",
      "Epoch 26/50\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 1.5801e-04 - rms: 0.0126 - mae: 0.0049\n",
      "Epoch 27/50\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 1.5653e-04 - rms: 0.0125 - mae: 0.0047\n",
      "Epoch 28/50\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 1.5755e-04 - rms: 0.0126 - mae: 0.0048\n",
      "Epoch 29/50\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 1.5514e-04 - rms: 0.0125 - mae: 0.0047\n",
      "Epoch 30/50\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 1.5314e-04 - rms: 0.0124 - mae: 0.0045\n",
      "Epoch 31/50\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 1.5576e-04 - rms: 0.0125 - mae: 0.0047\n",
      "Epoch 32/50\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 1.5358e-04 - rms: 0.0124 - mae: 0.0045\n",
      "Epoch 33/50\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 1.5460e-04 - rms: 0.0124 - mae: 0.0046\n",
      "Epoch 34/50\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 1.5492e-04 - rms: 0.0124 - mae: 0.0047\n",
      "Epoch 35/50\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 1.5548e-04 - rms: 0.0125 - mae: 0.0047\n",
      "Epoch 36/50\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 1.5394e-04 - rms: 0.0124 - mae: 0.0046\n",
      "Epoch 37/50\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 1.5492e-04 - rms: 0.0124 - mae: 0.0046\n",
      "Epoch 38/50\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 1.5251e-04 - rms: 0.0123 - mae: 0.0045\n",
      "Epoch 39/50\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 1.5425e-04 - rms: 0.0124 - mae: 0.0046\n",
      "Epoch 40/50\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 1.5263e-04 - rms: 0.0124 - mae: 0.0045\n",
      "Epoch 41/50\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 1.5330e-04 - rms: 0.0124 - mae: 0.0046\n",
      "Epoch 42/50\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 1.5275e-04 - rms: 0.0124 - mae: 0.0046\n",
      "Epoch 43/50\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 1.5199e-04 - rms: 0.0123 - mae: 0.0044\n",
      "Epoch 44/50\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 1.5358e-04 - rms: 0.0124 - mae: 0.0046\n",
      "Epoch 45/50\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 1.5131e-04 - rms: 0.0123 - mae: 0.0044\n",
      "Epoch 46/50\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 1.5280e-04 - rms: 0.0124 - mae: 0.0045\n",
      "Epoch 47/50\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 1.5177e-04 - rms: 0.0123 - mae: 0.0044\n",
      "Epoch 48/50\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 1.5215e-04 - rms: 0.0123 - mae: 0.0045\n",
      "Epoch 49/50\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 1.5218e-04 - rms: 0.0123 - mae: 0.0045\n",
      "Epoch 50/50\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 1.5139e-04 - rms: 0.0123 - mae: 0.0044\n"
     ]
    }
   ],
   "source": [
    "#### CNN autoencode\n",
    "df = pd.read_csv('training_cnn.csv')\n",
    "X, y = df.iloc[:,:-1], df.iloc[:, -1]\n",
    "auto, encode = make_and_train_autoencoder(X, metrics=METRICS)\n",
    "q = encode.predict(X)\n",
    "w = np.array(q)\n",
    "df = pd.DataFrame(data=w,index=None,columns=None)\n",
    "df['label'] = y\n",
    "df.to_csv('training_cnn_autoencoded_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a91c993f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "512/512 [==============================] - 4s 5ms/step - loss: 0.0089 - rms: 0.0827 - mae: 0.0403\n",
      "Epoch 2/50\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 0.0010 - rms: 0.0318 - mae: 0.0187\n",
      "Epoch 3/50\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 6.0896e-04 - rms: 0.0247 - mae: 0.0120\n",
      "Epoch 4/50\n",
      "512/512 [==============================] - 3s 7ms/step - loss: 5.0206e-04 - rms: 0.0224 - mae: 0.0104\n",
      "Epoch 5/50\n",
      "512/512 [==============================] - 3s 6ms/step - loss: 4.2421e-04 - rms: 0.0206 - mae: 0.0094\n",
      "Epoch 6/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 3.9751e-04 - rms: 0.0199 - mae: 0.0087\n",
      "Epoch 7/50\n",
      "512/512 [==============================] - 3s 6ms/step - loss: 3.9208e-04 - rms: 0.0198 - mae: 0.0086\n",
      "Epoch 8/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 3.8862e-04 - rms: 0.0197 - mae: 0.0086\n",
      "Epoch 9/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 3.8814e-04 - rms: 0.0197 - mae: 0.0086\n",
      "Epoch 10/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 3.8132e-04 - rms: 0.0195 - mae: 0.0086\n",
      "Epoch 11/50\n",
      "512/512 [==============================] - 3s 7ms/step - loss: 2.9375e-04 - rms: 0.0171 - mae: 0.0077\n",
      "Epoch 12/50\n",
      "512/512 [==============================] - 4s 8ms/step - loss: 2.6727e-04 - rms: 0.0163 - mae: 0.0070\n",
      "Epoch 13/50\n",
      "512/512 [==============================] - 3s 6ms/step - loss: 2.6353e-04 - rms: 0.0162 - mae: 0.0068\n",
      "Epoch 14/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 2.6125e-04 - rms: 0.0162 - mae: 0.0067\n",
      "Epoch 15/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 2.6189e-04 - rms: 0.0162 - mae: 0.0067\n",
      "Epoch 16/50\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 2.5993e-04 - rms: 0.0161 - mae: 0.0066\n",
      "Epoch 17/50\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 2.6070e-04 - rms: 0.0161 - mae: 0.0066\n",
      "Epoch 18/50\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 2.6083e-04 - rms: 0.0162 - mae: 0.0066\n",
      "Epoch 19/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 2.6034e-04 - rms: 0.0161 - mae: 0.0066\n",
      "Epoch 20/50\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 2.6040e-04 - rms: 0.0161 - mae: 0.0066\n",
      "Epoch 21/50\n",
      "512/512 [==============================] - 4s 8ms/step - loss: 2.6051e-04 - rms: 0.0161 - mae: 0.0066\n",
      "Epoch 22/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 2.5981e-04 - rms: 0.0161 - mae: 0.0066\n",
      "Epoch 23/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 2.5979e-04 - rms: 0.0161 - mae: 0.0065\n",
      "Epoch 24/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 2.6013e-04 - rms: 0.0161 - mae: 0.0066\n",
      "Epoch 25/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 2.5915e-04 - rms: 0.0161 - mae: 0.0065\n",
      "Epoch 26/50\n",
      "512/512 [==============================] - 3s 6ms/step - loss: 2.5919e-04 - rms: 0.0161 - mae: 0.0065\n",
      "Epoch 27/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 2.5949e-04 - rms: 0.0161 - mae: 0.0065\n",
      "Epoch 28/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 2.5898e-04 - rms: 0.0161 - mae: 0.0065\n",
      "Epoch 29/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 2.5875e-04 - rms: 0.0161 - mae: 0.0065\n",
      "Epoch 30/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 2.5961e-04 - rms: 0.0161 - mae: 0.0065\n",
      "Epoch 31/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 2.5871e-04 - rms: 0.0161 - mae: 0.0065\n",
      "Epoch 32/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 2.5896e-04 - rms: 0.0161 - mae: 0.0065\n",
      "Epoch 33/50\n",
      "512/512 [==============================] - 3s 6ms/step - loss: 2.5836e-04 - rms: 0.0161 - mae: 0.0065\n",
      "Epoch 34/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 2.5932e-04 - rms: 0.0161 - mae: 0.0065\n",
      "Epoch 35/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 2.5846e-04 - rms: 0.0161 - mae: 0.0065\n",
      "Epoch 36/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 2.5931e-04 - rms: 0.0161 - mae: 0.0065\n",
      "Epoch 37/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 2.5851e-04 - rms: 0.0161 - mae: 0.0065\n",
      "Epoch 38/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 2.5915e-04 - rms: 0.0161 - mae: 0.0065\n",
      "Epoch 39/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 2.5935e-04 - rms: 0.0161 - mae: 0.0065\n",
      "Epoch 40/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 2.5844e-04 - rms: 0.0161 - mae: 0.0065\n",
      "Epoch 41/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 2.5834e-04 - rms: 0.0161 - mae: 0.0065\n",
      "Epoch 42/50\n",
      "512/512 [==============================] - 3s 6ms/step - loss: 2.5787e-04 - rms: 0.0161 - mae: 0.0064\n",
      "Epoch 43/50\n",
      "512/512 [==============================] - 3s 6ms/step - loss: 2.5738e-04 - rms: 0.0160 - mae: 0.0064\n",
      "Epoch 44/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 2.5753e-04 - rms: 0.0160 - mae: 0.0064\n",
      "Epoch 45/50\n",
      "512/512 [==============================] - 3s 6ms/step - loss: 2.5848e-04 - rms: 0.0161 - mae: 0.0065\n",
      "Epoch 46/50\n",
      "512/512 [==============================] - 3s 6ms/step - loss: 2.5808e-04 - rms: 0.0161 - mae: 0.0064\n",
      "Epoch 47/50\n",
      "512/512 [==============================] - 3s 6ms/step - loss: 2.5785e-04 - rms: 0.0161 - mae: 0.0064\n",
      "Epoch 48/50\n",
      "512/512 [==============================] - 3s 6ms/step - loss: 2.5806e-04 - rms: 0.0161 - mae: 0.0065\n",
      "Epoch 49/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 2.5769e-04 - rms: 0.0161 - mae: 0.0064\n",
      "Epoch 50/50\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 2.5766e-04 - rms: 0.0161 - mae: 0.0064\n"
     ]
    }
   ],
   "source": [
    "#### smote autoencode\n",
    "df = pd.read_csv('training_smote.csv')\n",
    "X, y = df.iloc[:,:-1], df.iloc[:, -1]\n",
    "auto, encode = make_and_train_autoencoder(X, metrics=METRICS)\n",
    "q = encode.predict(X)\n",
    "w = np.array(q)\n",
    "df = pd.DataFrame(data=w,index=None,columns=None)\n",
    "df['label'] = y\n",
    "df.to_csv('training_smote_autoencoded_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e48d0007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "146/146 [==============================] - 2s 5ms/step - loss: 0.0216 - rms: 0.0705 - mae: 0.0258\n",
      "Epoch 2/50\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 0.0044 - rms: 0.0662 - mae: 0.0434\n",
      "Epoch 3/50\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 0.0024 - rms: 0.0491 - mae: 0.0316\n",
      "Epoch 4/50\n",
      "146/146 [==============================] - 1s 6ms/step - loss: 0.0017 - rms: 0.0412 - mae: 0.0265\n",
      "Epoch 5/50\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 0.0012 - rms: 0.0339 - mae: 0.0210\n",
      "Epoch 6/50\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 7.6816e-04 - rms: 0.0277 - mae: 0.0166\n",
      "Epoch 7/50\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 5.3808e-04 - rms: 0.0232 - mae: 0.0130\n",
      "Epoch 8/50\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 4.4279e-04 - rms: 0.0210 - mae: 0.0111\n",
      "Epoch 9/50\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 3.9817e-04 - rms: 0.0200 - mae: 0.0100\n",
      "Epoch 10/50\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 3.6701e-04 - rms: 0.0192 - mae: 0.0093\n",
      "Epoch 11/50\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 3.4877e-04 - rms: 0.0187 - mae: 0.0089\n",
      "Epoch 12/50\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 3.3243e-04 - rms: 0.0182 - mae: 0.0086\n",
      "Epoch 13/50\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 3.1945e-04 - rms: 0.0179 - mae: 0.0083\n",
      "Epoch 14/50\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 3.0730e-04 - rms: 0.0175 - mae: 0.0081\n",
      "Epoch 15/50\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 2.9889e-04 - rms: 0.0173 - mae: 0.0081\n",
      "Epoch 16/50\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 2.8778e-04 - rms: 0.0170 - mae: 0.0078\n",
      "Epoch 17/50\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 2.7919e-04 - rms: 0.0167 - mae: 0.0076\n",
      "Epoch 18/50\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 2.7476e-04 - rms: 0.0166 - mae: 0.0075\n",
      "Epoch 19/50\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 2.6938e-04 - rms: 0.0164 - mae: 0.0074\n",
      "Epoch 20/50\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 2.6323e-04 - rms: 0.0162 - mae: 0.0071\n",
      "Epoch 21/50\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 2.5992e-04 - rms: 0.0161 - mae: 0.0071\n",
      "Epoch 22/50\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 2.5588e-04 - rms: 0.0160 - mae: 0.0069\n",
      "Epoch 23/50\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 2.5215e-04 - rms: 0.0159 - mae: 0.0067\n",
      "Epoch 24/50\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 2.4911e-04 - rms: 0.0158 - mae: 0.0066\n",
      "Epoch 25/50\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 2.4797e-04 - rms: 0.0157 - mae: 0.0065\n",
      "Epoch 26/50\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 2.4646e-04 - rms: 0.0157 - mae: 0.0064\n",
      "Epoch 27/50\n",
      "146/146 [==============================] - 1s 6ms/step - loss: 2.4539e-04 - rms: 0.0157 - mae: 0.0064\n",
      "Epoch 28/50\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 2.4131e-04 - rms: 0.0155 - mae: 0.0062\n",
      "Epoch 29/50\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 2.3877e-04 - rms: 0.0155 - mae: 0.0061\n",
      "Epoch 30/50\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 2.3962e-04 - rms: 0.0155 - mae: 0.0061\n",
      "Epoch 31/50\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 2.3785e-04 - rms: 0.0154 - mae: 0.0061\n",
      "Epoch 32/50\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 2.3465e-04 - rms: 0.0153 - mae: 0.0059\n",
      "Epoch 33/50\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 2.3364e-04 - rms: 0.0153 - mae: 0.0060\n",
      "Epoch 34/50\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 2.2976e-04 - rms: 0.0152 - mae: 0.0058\n",
      "Epoch 35/50\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 2.2626e-04 - rms: 0.0150 - mae: 0.0057\n",
      "Epoch 36/50\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 2.2862e-04 - rms: 0.0151 - mae: 0.0059\n",
      "Epoch 37/50\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 2.2381e-04 - rms: 0.0150 - mae: 0.0057\n",
      "Epoch 38/50\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 2.2561e-04 - rms: 0.0150 - mae: 0.0059\n",
      "Epoch 39/50\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 2.2118e-04 - rms: 0.0149 - mae: 0.0057\n",
      "Epoch 40/50\n",
      "146/146 [==============================] - 1s 6ms/step - loss: 2.1972e-04 - rms: 0.0148 - mae: 0.0057\n",
      "Epoch 41/50\n",
      "146/146 [==============================] - 1s 6ms/step - loss: 2.1964e-04 - rms: 0.0148 - mae: 0.0057\n",
      "Epoch 42/50\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 2.1697e-04 - rms: 0.0147 - mae: 0.0057\n",
      "Epoch 43/50\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 2.1675e-04 - rms: 0.0147 - mae: 0.0057\n",
      "Epoch 44/50\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 2.1701e-04 - rms: 0.0147 - mae: 0.0057\n",
      "Epoch 45/50\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 2.1456e-04 - rms: 0.0146 - mae: 0.0056\n",
      "Epoch 46/50\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 2.1455e-04 - rms: 0.0146 - mae: 0.0056\n",
      "Epoch 47/50\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 2.1593e-04 - rms: 0.0147 - mae: 0.0057\n",
      "Epoch 48/50\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 2.1157e-04 - rms: 0.0145 - mae: 0.0054\n",
      "Epoch 49/50\n",
      "146/146 [==============================] - 1s 8ms/step - loss: 2.1369e-04 - rms: 0.0146 - mae: 0.0056\n",
      "Epoch 50/50\n",
      "146/146 [==============================] - 1s 6ms/step - loss: 2.1088e-04 - rms: 0.0145 - mae: 0.0054\n"
     ]
    }
   ],
   "source": [
    "#### rus autoencode\n",
    "df = pd.read_csv('training_rus.csv')\n",
    "X, y = df.iloc[:,:-1], df.iloc[:, -1]\n",
    "auto, encode = make_and_train_autoencoder(X, metrics=METRICS)\n",
    "q = encode.predict(X)\n",
    "w = np.array(q)\n",
    "df = pd.DataFrame(data=w,index=None,columns=None)\n",
    "df['label'] = y\n",
    "df.to_csv('training_rus_autoencoded_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1593ed68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "329/329 [==============================] - 4s 5ms/step - loss: 0.0087 - rms: 0.0783 - mae: 0.0384\n",
      "Epoch 2/50\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 0.0013 - rms: 0.0361 - mae: 0.0217\n",
      "Epoch 3/50\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 8.3718e-04 - rms: 0.0289 - mae: 0.0161\n",
      "Epoch 4/50\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 5.9949e-04 - rms: 0.0245 - mae: 0.0126\n",
      "Epoch 5/50\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 4.9944e-04 - rms: 0.0223 - mae: 0.0114\n",
      "Epoch 6/50\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 4.1751e-04 - rms: 0.0204 - mae: 0.0104\n",
      "Epoch 7/50\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 3.4357e-04 - rms: 0.0185 - mae: 0.0091\n",
      "Epoch 8/50\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 2.9750e-04 - rms: 0.0172 - mae: 0.0083\n",
      "Epoch 9/50\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 2.7286e-04 - rms: 0.0165 - mae: 0.0077\n",
      "Epoch 10/50\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 2.5769e-04 - rms: 0.0161 - mae: 0.0072\n",
      "Epoch 11/50\n",
      "329/329 [==============================] - 3s 8ms/step - loss: 2.4802e-04 - rms: 0.0157 - mae: 0.0069\n",
      "Epoch 12/50\n",
      "329/329 [==============================] - 2s 7ms/step - loss: 2.4090e-04 - rms: 0.0155 - mae: 0.0067\n",
      "Epoch 13/50\n",
      "329/329 [==============================] - 3s 8ms/step - loss: 2.3400e-04 - rms: 0.0153 - mae: 0.0065\n",
      "Epoch 14/50\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 2.2849e-04 - rms: 0.0151 - mae: 0.0064\n",
      "Epoch 15/50\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 2.1397e-04 - rms: 0.0146 - mae: 0.0062\n",
      "Epoch 16/50\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 1.9955e-04 - rms: 0.0141 - mae: 0.0061\n",
      "Epoch 17/50\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 1.8069e-04 - rms: 0.0134 - mae: 0.0060\n",
      "Epoch 18/50\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 1.5913e-04 - rms: 0.0126 - mae: 0.0056\n",
      "Epoch 19/50\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 1.4521e-04 - rms: 0.0121 - mae: 0.0050\n",
      "Epoch 20/50\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 1.3890e-04 - rms: 0.0118 - mae: 0.0045\n",
      "Epoch 21/50\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 1.3704e-04 - rms: 0.0117 - mae: 0.0044\n",
      "Epoch 22/50\n",
      "329/329 [==============================] - 1s 5ms/step - loss: 1.3588e-04 - rms: 0.0117 - mae: 0.0043\n",
      "Epoch 23/50\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 1.3470e-04 - rms: 0.0116 - mae: 0.0042\n",
      "Epoch 24/50\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 1.3447e-04 - rms: 0.0116 - mae: 0.0042\n",
      "Epoch 25/50\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 1.3415e-04 - rms: 0.0116 - mae: 0.0042\n",
      "Epoch 26/50\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 1.3347e-04 - rms: 0.0116 - mae: 0.0042\n",
      "Epoch 27/50\n",
      "329/329 [==============================] - 1s 5ms/step - loss: 1.3371e-04 - rms: 0.0116 - mae: 0.0042\n",
      "Epoch 28/50\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 1.3507e-04 - rms: 0.0116 - mae: 0.0043\n",
      "Epoch 29/50\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 1.3297e-04 - rms: 0.0115 - mae: 0.0042\n",
      "Epoch 30/50\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 1.3262e-04 - rms: 0.0115 - mae: 0.0042\n",
      "Epoch 31/50\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 1.3222e-04 - rms: 0.0115 - mae: 0.0042\n",
      "Epoch 32/50\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 1.3317e-04 - rms: 0.0115 - mae: 0.0043\n",
      "Epoch 33/50\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 1.3094e-04 - rms: 0.0114 - mae: 0.0042\n",
      "Epoch 34/50\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 1.3190e-04 - rms: 0.0115 - mae: 0.0043\n",
      "Epoch 35/50\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 1.3123e-04 - rms: 0.0115 - mae: 0.0043\n",
      "Epoch 36/50\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 1.3097e-04 - rms: 0.0114 - mae: 0.0043\n",
      "Epoch 37/50\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 1.3059e-04 - rms: 0.0114 - mae: 0.0044\n",
      "Epoch 38/50\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 1.2565e-04 - rms: 0.0112 - mae: 0.0044\n",
      "Epoch 39/50\n",
      "329/329 [==============================] - 1s 5ms/step - loss: 1.2076e-04 - rms: 0.0110 - mae: 0.0045\n",
      "Epoch 40/50\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 1.1555e-04 - rms: 0.0107 - mae: 0.0044\n",
      "Epoch 41/50\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 1.1360e-04 - rms: 0.0107 - mae: 0.0044\n",
      "Epoch 42/50\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 1.1124e-04 - rms: 0.0105 - mae: 0.0043\n",
      "Epoch 43/50\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 1.1011e-04 - rms: 0.0105 - mae: 0.0043\n",
      "Epoch 44/50\n",
      "329/329 [==============================] - 2s 7ms/step - loss: 1.0943e-04 - rms: 0.0105 - mae: 0.0043\n",
      "Epoch 45/50\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 1.0938e-04 - rms: 0.0105 - mae: 0.0042\n",
      "Epoch 46/50\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 1.0792e-04 - rms: 0.0104 - mae: 0.0042\n",
      "Epoch 47/50\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 1.0744e-04 - rms: 0.0104 - mae: 0.0042\n",
      "Epoch 48/50\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 1.0744e-04 - rms: 0.0104 - mae: 0.0042\n",
      "Epoch 49/50\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 1.0760e-04 - rms: 0.0104 - mae: 0.0042\n",
      "Epoch 50/50\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 1.0692e-04 - rms: 0.0103 - mae: 0.0042\n"
     ]
    }
   ],
   "source": [
    "#### CNN autoencode\n",
    "df = pd.read_csv('training_set.csv')\n",
    "X, y = df.iloc[:,:-1], df.iloc[:, -1]\n",
    "auto, encode = make_and_train_autoencoder(X, metrics=METRICS)\n",
    "q = encode.predict(X)\n",
    "w = np.array(q)\n",
    "df = pd.DataFrame(data=w,index=None,columns=None)\n",
    "df['label'] = y\n",
    "df.to_csv('training_autoencoded_16.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d51e9d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.649962</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.190692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.881780</td>\n",
       "      <td>0.372529</td>\n",
       "      <td>0.372442</td>\n",
       "      <td>0.317951</td>\n",
       "      <td>0.418032</td>\n",
       "      <td>0.309938</td>\n",
       "      <td>0.692874</td>\n",
       "      <td>0.296392</td>\n",
       "      <td>0.337929</td>\n",
       "      <td>0.370286</td>\n",
       "      <td>0.408662</td>\n",
       "      <td>0.417658</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.991434</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.337706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.168818</td>\n",
       "      <td>0.326303</td>\n",
       "      <td>0.450684</td>\n",
       "      <td>0.327323</td>\n",
       "      <td>0.582274</td>\n",
       "      <td>0.593707</td>\n",
       "      <td>1.003968</td>\n",
       "      <td>0.519556</td>\n",
       "      <td>0.444000</td>\n",
       "      <td>0.629197</td>\n",
       "      <td>0.640001</td>\n",
       "      <td>0.642415</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.417387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.090249</td>\n",
       "      <td>0.275374</td>\n",
       "      <td>0.627792</td>\n",
       "      <td>0.322801</td>\n",
       "      <td>0.596119</td>\n",
       "      <td>0.638291</td>\n",
       "      <td>0.446818</td>\n",
       "      <td>0.255099</td>\n",
       "      <td>0.390511</td>\n",
       "      <td>0.934454</td>\n",
       "      <td>0.368380</td>\n",
       "      <td>0.666986</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.580099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.221034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.876561</td>\n",
       "      <td>0.287392</td>\n",
       "      <td>0.405546</td>\n",
       "      <td>0.339411</td>\n",
       "      <td>0.527713</td>\n",
       "      <td>0.502262</td>\n",
       "      <td>0.591283</td>\n",
       "      <td>0.191841</td>\n",
       "      <td>0.336930</td>\n",
       "      <td>0.346187</td>\n",
       "      <td>0.464837</td>\n",
       "      <td>0.692884</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.381035</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.146306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.677030</td>\n",
       "      <td>0.191636</td>\n",
       "      <td>0.311483</td>\n",
       "      <td>0.235915</td>\n",
       "      <td>0.525853</td>\n",
       "      <td>0.356670</td>\n",
       "      <td>0.379686</td>\n",
       "      <td>0.193311</td>\n",
       "      <td>0.242482</td>\n",
       "      <td>0.166571</td>\n",
       "      <td>0.376768</td>\n",
       "      <td>0.503467</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20995</th>\n",
       "      <td>0.684400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.206728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.071134</td>\n",
       "      <td>0.310432</td>\n",
       "      <td>0.467092</td>\n",
       "      <td>0.346199</td>\n",
       "      <td>0.678461</td>\n",
       "      <td>0.534257</td>\n",
       "      <td>0.678845</td>\n",
       "      <td>0.291551</td>\n",
       "      <td>0.414729</td>\n",
       "      <td>0.382163</td>\n",
       "      <td>0.497212</td>\n",
       "      <td>0.693161</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20996</th>\n",
       "      <td>0.388258</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.169930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.687806</td>\n",
       "      <td>0.216306</td>\n",
       "      <td>0.211961</td>\n",
       "      <td>0.283847</td>\n",
       "      <td>0.358786</td>\n",
       "      <td>0.147896</td>\n",
       "      <td>0.528977</td>\n",
       "      <td>0.215841</td>\n",
       "      <td>0.165972</td>\n",
       "      <td>0.228109</td>\n",
       "      <td>0.295330</td>\n",
       "      <td>0.316185</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20997</th>\n",
       "      <td>0.380552</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.789283</td>\n",
       "      <td>0.088973</td>\n",
       "      <td>0.181558</td>\n",
       "      <td>0.238039</td>\n",
       "      <td>0.465793</td>\n",
       "      <td>0.475744</td>\n",
       "      <td>0.451526</td>\n",
       "      <td>0.165691</td>\n",
       "      <td>0.389922</td>\n",
       "      <td>0.230509</td>\n",
       "      <td>0.508838</td>\n",
       "      <td>0.558954</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20998</th>\n",
       "      <td>0.832526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.237932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.405218</td>\n",
       "      <td>0.393873</td>\n",
       "      <td>0.442044</td>\n",
       "      <td>0.413843</td>\n",
       "      <td>0.748954</td>\n",
       "      <td>0.694703</td>\n",
       "      <td>0.759271</td>\n",
       "      <td>0.300525</td>\n",
       "      <td>0.455218</td>\n",
       "      <td>0.391290</td>\n",
       "      <td>0.508775</td>\n",
       "      <td>0.700879</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20999</th>\n",
       "      <td>0.494256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.217007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.841658</td>\n",
       "      <td>0.004947</td>\n",
       "      <td>0.676349</td>\n",
       "      <td>0.252016</td>\n",
       "      <td>0.435053</td>\n",
       "      <td>0.804257</td>\n",
       "      <td>0.438854</td>\n",
       "      <td>0.348692</td>\n",
       "      <td>0.436221</td>\n",
       "      <td>0.803369</td>\n",
       "      <td>0.254638</td>\n",
       "      <td>0.512936</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0    1         2    3         4         5         6         7  \\\n",
       "0      0.649962  0.0  0.190692  0.0  0.881780  0.372529  0.372442  0.317951   \n",
       "1      0.991434  0.0  0.337706  0.0  1.168818  0.326303  0.450684  0.327323   \n",
       "2      0.417387  0.0  0.255210  0.0  1.090249  0.275374  0.627792  0.322801   \n",
       "3      0.580099  0.0  0.221034  0.0  0.876561  0.287392  0.405546  0.339411   \n",
       "4      0.381035  0.0  0.146306  0.0  0.677030  0.191636  0.311483  0.235915   \n",
       "...         ...  ...       ...  ...       ...       ...       ...       ...   \n",
       "20995  0.684400  0.0  0.206728  0.0  1.071134  0.310432  0.467092  0.346199   \n",
       "20996  0.388258  0.0  0.169930  0.0  0.687806  0.216306  0.211961  0.283847   \n",
       "20997  0.380552  0.0  0.135332  0.0  0.789283  0.088973  0.181558  0.238039   \n",
       "20998  0.832526  0.0  0.237932  0.0  1.405218  0.393873  0.442044  0.413843   \n",
       "20999  0.494256  0.0  0.217007  0.0  0.841658  0.004947  0.676349  0.252016   \n",
       "\n",
       "              8         9        10        11        12        13        14  \\\n",
       "0      0.418032  0.309938  0.692874  0.296392  0.337929  0.370286  0.408662   \n",
       "1      0.582274  0.593707  1.003968  0.519556  0.444000  0.629197  0.640001   \n",
       "2      0.596119  0.638291  0.446818  0.255099  0.390511  0.934454  0.368380   \n",
       "3      0.527713  0.502262  0.591283  0.191841  0.336930  0.346187  0.464837   \n",
       "4      0.525853  0.356670  0.379686  0.193311  0.242482  0.166571  0.376768   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "20995  0.678461  0.534257  0.678845  0.291551  0.414729  0.382163  0.497212   \n",
       "20996  0.358786  0.147896  0.528977  0.215841  0.165972  0.228109  0.295330   \n",
       "20997  0.465793  0.475744  0.451526  0.165691  0.389922  0.230509  0.508838   \n",
       "20998  0.748954  0.694703  0.759271  0.300525  0.455218  0.391290  0.508775   \n",
       "20999  0.435053  0.804257  0.438854  0.348692  0.436221  0.803369  0.254638   \n",
       "\n",
       "             15  label  \n",
       "0      0.417658    0.0  \n",
       "1      0.642415    1.0  \n",
       "2      0.666986    0.0  \n",
       "3      0.692884    0.0  \n",
       "4      0.503467    0.0  \n",
       "...         ...    ...  \n",
       "20995  0.693161    0.0  \n",
       "20996  0.316185    1.0  \n",
       "20997  0.558954    0.0  \n",
       "20998  0.700879    0.0  \n",
       "20999  0.512936    0.0  \n",
       "\n",
       "[21000 rows x 17 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e319e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
